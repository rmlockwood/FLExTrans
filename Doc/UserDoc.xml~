<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE lingPaper PUBLIC "-//XMLmind//DTD XLingPap//EN"
"XLingPap.dtd">
<lingPaper
automaticallywrapinterlinears="yes"
version="2.20.0"
><frontMatter
><title
><object
type="tFlextrans"
></object
> User Documentation</title
><author
></author
><emailAddress
>flextrans.help@gmail.com</emailAddress
><date
>9 May, 2022</date
><version
>FLExTrans 3.5</version
><contents
showLevel="4"
></contents
><abstract
><p
>This document describes how to use the <object
type="tFlextrans"
></object
> machine translation system. See <sectionRef
sec="sReferenceDocs"
showTitle="numberOnly"
textBefore="singular"
></sectionRef
> for other documentation.</p
><p
><comment
>Ideas for content for this document</comment
></p
><p
><comment
>Sections to read in the thesis to get oriented. (temporary)</comment
></p
><p
><comment
>Installation</comment
></p
><p
><comment
>Sample projects, understanding, modifying.</comment
></p
><p
><comment
>How to ... FAQs</comment
></p
><p
><comment
>Things that were in the presentation to LSDev (variants [inflectional &amp; normal], </comment
></p
><p
><comment
>Rule examples</comment
></p
><p
><comment
>Overview with diagram</comment
></p
><p
><comment
>How to edit using XXE</comment
></p
><p
><comment
>Each module explained</comment
></p
><p
><comment
>Configuration file</comment
></p
><p
><comment
>Troubleshooting</comment
></p
></abstract
></frontMatter
><section1
id="sIntro"
><secTitle
>Introduction</secTitle
><p
><object
type="tFlextrans"
></object
> is a rule-based machine translation system. It was first developed in 2015 (<citation
paren="final"
ref="rLockwood15"
></citation
>. It marries the power of the <object
type="tProgramName"
>Apertium</object
> (<citation
paren="none"
ref="rApertiumSite"
></citation
>) transfer engine with the outstanding lexical model and usability of <object
type="tFlexx"
></object
>.</p
><figure
align="center"
id="f1"
><chart
><img
XeLaTeXSpecial="scaled='500'"
cssSpecial="height:50%;"
src="Images/diagram%20v3.png"
></img
></chart
></figure
><p
><object
type="tFlextrans"
></object
> is composed basically of two language databases, a list of transfer rules and a series of programs that do the work. The language databases, one for the source language and one for the target language, are in the form of <object
type="tFlexx"
></object
> projects. A <object
type="tFlexx"
></object
> project stores, among other things, a lexicon, grammar settings and a database of texts. The transfer rules are in the form of a text file in XML format. The core programs are the analysis engine, the transfer engine and the synthesis engine. A text in the source language first goes through the analysis process where words are broken down into morphemes. Then the “analyzed” text is transformed into target morphemes and rearranged as necessary in the transfer process. Lastly, the target morphemes are put together into target words in the synthesis process. The end result is a text in the target language.</p
><p
><object
type="tFlextrans"
></object
>, as a program, consists of several different modules that are run within the <object
type="tFlexxTools"
></object
><endnote
id="nFlexTools"
><p
><object
type="tFlexxTools"
></object
> is a general purpose program for running python scripts against a <object
type="tFlexx"
></object
> database.</p
></endnote
> program. Upon installation, <object
type="tFlexxTools"
></object
> is populated with three collections of modules for common <object
type="tFlextrans"
></object
> tasks. <comment
>Maybe refer to a new section on how FlexTools and collections work. Should this mention deleting lock files?</comment
></p
></section1
><section1
id="sGettingStarted"
><secTitle
>Getting Started</secTitle
><p
>The basic steps for machine translation with <object
type="tFlextrans"
></object
> are as follows:</p
><ol
><li
>Analyze the text you want to translate in the source <object
type="tFlexx"
></object
> project.</li
><li
>Link lexical senses that are in the source text to senses in the target <object
type="tFlexx"
></object
> project using the <object
type="tSenseLinker"
></object
></li
><li
>Write transfer rules that convert source words and phrases to target words and phrases.</li
><li
>Run the seven basic <object
type="tFlextrans"
></object
> modules.</li
></ol
><p
>Let’s look at each step in more detail.<comment
> For a more thorough treatment of each step see FLExTrans Steps in More Detail.</comment
></p
><p
>(It is assumed that you have gone through the <link
href="https://software.sil.org/flextrans/installation/"
>installation</link
> steps as given on the <object
type="tFlextrans"
></object
> website and that you have <object
type="tFlextrans"
></object
> working for the sample projects. It is also assumed that you have two <object
type="tFlexx"
></object
> projects to use as source and target projects for the following steps.)</p
><section2
id="sAnalyze"
><secTitle
>Analyze the Source Text</secTitle
><ol
><li
>Create a new text in <object
type="tFlexx"
></object
>.</li
><li
>Paste in some text. (Start with a simple text; perhaps just one sentence.)</li
><li
>Analyze this text.<ol
><li
>Divide each word into its morphemes.</li
><li
>Accept the analysis of each word.</li
></ol
></li
></ol
><p
>Word glosses, word categories and free translations are not necessary. A fully analyzed text will look something like <exampleRef
letter="xAnalyzedText"
num="xAnalyzedText"
></exampleRef
> below.</p
><example
num="xAnalyzedText"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial=" height:60%"
src="Images/AnalyzedText.PNG"
></img
></chart
></example
><p
>Note: Word gloss and category are hidden as well as free translation.</p
><p
><comment
>Advanced info. for the later section:</comment
></p
><p
><comment
>All affixes and clitics need to have unique glosses</comment
></p
><p
><comment
>Use the parser for faster analysis.</comment
></p
></section2
><section2
id="sPrepSteps"
><secTitle
>Preparatory Steps</secTitle
><ol
><li
>Edit the configuration file and change two values.<ol
><li
>Open <object
type="tTool"
>Notepad</object
></li
><li
>Select File &gt; Open from the menu.</li
><li
>Navigate to the install folder (typically Documents\FlexTools2.0).</li
><li
>Select the <object
type="tFilename"
>FlexTrans.config</object
> file and hit <object
type="tItalic"
>Enter</object
>.</li
><li
>Change these two values:<table
border="1"
><tr
><th
>Value</th
><th
>Change to</th
></tr
><tr
><td
><object
type="tCourier"
>SourceTextName</object
></td
><td
><object
type="tItalic"
>The title of the text you want to translate (from the source </object
><object
type="tFlexx"
></object
> <object
type="tItalic"
>project)</object
></td
></tr
><tr
><td
><object
type="tCourier"
>TargetProject</object
></td
><td
><object
type="tItalic"
>The name of your target </object
><object
type="tFlexx"
></object
><object
type="tItalic"
> project</object
></td
></tr
></table
></li
></ol
></li
><li
>Add two custom fields to your source <object
type="tFlexx"
></object
> project. This is where link information to the target senses is kept.<ol
><li
>In your source <object
type="tFlexx"
></object
> project, go to the Lexicon area</li
><li
>From the menu select Tools &gt; Configure &gt; Custom Fields</li
><li
>Click Add and use the following settings:<ol
><li
>Custom Field Name: Target Equivalent<endnote
id="nCustomFieldNames"
><p
>You may choose different names for the custom fields, but you also have to update the configuration file to match these names. The names <object
type="tBold"
>Target Equivalent</object
> and <object
type="tBold"
>Target Sense Number</object
> are already set in the configuration file that gets installed with <object
type="tFlextrans"
></object
>.</p
></endnote
></li
><li
>Location: <object
type="tUnderline"
>Sense</object
></li
><li
>Type: Single-line Text</li
><li
>Writing Systems(s): First Analysis Writing System</li
></ol
></li
><li
>Click Add again and use the following settings for a second custom field:<ol
><li
>Custom Field Name: Target Sense Number<endnoteRef
note="nCustomFieldNames"
></endnoteRef
></li
><li
>Location: <object
type="tUnderline"
>Sense</object
></li
><li
>Type: Single-line Text</li
><li
>Writing Systems(s): First Analysis Writing System</li
></ol
></li
><li
>Click OK</li
></ol
></li
><li
>Close the <object
type="tFlexx"
></object
> source and target projects.</li
><li
>Start <object
type="tFlexxTools"
></object
>. See <appendixRef
app="sStartFlextools"
></appendixRef
> for step-by-step instructions. It should look like <exampleRef
letter="xFirstStart"
num="xFirstStart"
></exampleRef
>.<example
num="xFirstStart"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial=" height:60%"
src="Images/FLExTransModules.png"
></img
></chart
></example
></li
><li
>Click on the <img
cssSpecial="Width:5%"
src="Images/DatabaseBut.PNG"
></img
> button and choose your source database, i.e. <object
type="tFlexx"
></object
> project.</li
></ol
></section2
><section2
id="sLinkSenses"
><secTitle
>Link Senses</secTitle
><ol
><li
>Click on the <img
cssSpecial="Width:5%"
src="Images/CollectionsBut.PNG"
></img
> button which will bring up a list of collections as shown in <exampleRef
letter="xLinkerInCollections"
num="xLinkerInCollections"
></exampleRef
>.<example
num="xLinkerInCollections"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/LinkerInCollections.png"
></img
></chart
></example
></li
><li
>Double-click on <object
type="tCollection"
>FLExTrans Tools</object
> in the list and you’ll see this:<example
num="xToolsCollection"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/ToolsCollection.png"
></img
></chart
></example
></li
><li
>Click on <object
type="tCollection"
>FLExTrans.Sense Linker Tool</object
> in the list.<example
num="xLinkerModule"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/LinkerModule.png"
></img
></chart
></example
></li
><li
>Click on the <img
cssSpecial="Width:5%"
src="Images/RunModifyBut.PNG"
></img
> button to run the module. Click OK on the message box that comes up to confirm you want to change <object
type="tFlexx"
></object
> data. You’ll now see the <object
type="tSenseLinker"
></object
> with no links yet established. The window will look something like this:<example
num="xLinkerNoLinks"
><chart
><img
src="Images/SenseLinkerNoLinks.png"
></img
></chart
></example
></li
><li
>Link each sense. (More details in <sectionRef
sec="sLinker"
showTitle="numberOnly"
textBefore="singular"
></sectionRef
>) <comment
>Need a new image</comment
><ol
><li
>For blue rows that look good, simply check the check box in the <object
type="tBold"
>Link It</object
> column.</li
><li
>For red rows pick the appropriate target sense in the drop-down list, then double-click in the <object
type="tBold"
>Target Head Word</object
> column for that row.</li
></ol
></li
><li
>Click OK</li
></ol
><p
>Now you have senses linked from source project to the target. You haven’t created anything in the target project yet, but you have done the preparatory work.</p
><p
><comment
>Advanced info. for the later section:</comment
></p
><p
><comment
>Explain why senses are linked. Bilingual dictionary, etc.</comment
></p
></section2
><section2
id="sWriteRules"
><secTitle
>Write Transfer Rules</secTitle
><p
>In this section, as an exercise, we are going to write a simple rule that removes affixes from words of a certain category. We’ll modify an existing rule to do this.</p
><ol
><li
>Navigate to your installation folder.</li
><li
>Open the file <object
type="tFilename"
>transfer_rules.t1x</object
> in <object
type="tXMLmindXMLEditor"
></object
>. It should look something like <exampleRef
letter="xInitialSampleRules"
num="xInitialSampleRules"
></exampleRef
>. This is the transfer rules file that works with the sample projects.<example
num="xInitialSampleRules"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleInitial.PNG"
></img
></chart
></example
></li
><li
>Expand the <object
type="tRuleElemInXXE"
>rule </object
> element and also the <object
type="tRuleElemInXXE"
>output</object
> element so that it looks like <exampleRef
letter="xRulesSampleVerbRule"
num="xRulesSampleVerbRule"
></exampleRef
>.<example
num="xRulesSampleVerbRule"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleVerbRule.PNG"
></img
></chart
></example
></li
><li
>Pick a category that you are going to process. For this example let’s use noun, abbreviated “n”.</li
><li
>Change the <object
type="tRuleElemInXXE"
>rule</object
> comment shown in blue to “Nouns”</li
><li
>We need to change the <object
type="tRuleElemInXXE"
>pattern</object
> element so it matches nouns. Change the <object
type="tRuleElemInXXE"
>item</object
> element to “c_n”. We will use this to mean: category noun. Category noun gets defined in a later step.</li
><li
>Remove the two <object
type="tRuleElemInXXE"
>literal tag</object
> elements by clicking on the word “literal” and pressing the delete key. The rule should now look like <exampleRef
letter="xRulesSampleNounRule"
num="xRulesSampleNounRule"
></exampleRef
>.<example
num="xRulesSampleNounRule"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleNounRule.PNG"
></img
></chart
></example
></li
><li
>Expand the <object
type="tRuleElemInXXE"
>Categories</object
> element and the second <object
type="tRuleElemInXXE"
>category</object
> element and it should look like <exampleRef
letter="xRulesSampleCatsBefore"
num="xRulesSampleCatsBefore"
></exampleRef
>.<example
num="xRulesSampleCatsBefore"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleCatsBefore.PNG"
></img
></chart
></example
></li
><li
>Change “c_v” to “c_n” in the <object
type="tRuleElemInXXE"
>category</object
> element and “v” to “n” in both <object
type="tRuleElemInXXE"
>tags</object
> elements. Now it should look something like <exampleRef
letter="xRulesSampleCatsAfter"
num="xRulesSampleCatsAfter"
></exampleRef
>. Category “c_n” is now defined as the single tag “n” or the tag “n” followed by any other tag, i.e. affixes and the like.<example
num="xRulesSampleCatsAfter"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleCatsAfter.PNG"
></img
></chart
></example
></li
><li
>Expand the <object
type="tRuleElemInXXE"
>Attributes</object
> element and the second <object
type="tRuleElemInXXE"
>attribute</object
> element and it should look like <exampleRef
letter="xRulesSampleAttribs"
num="xRulesSampleAttribs"
></exampleRef
>. Note that we already have a tag for a noun.<example
num="xRulesSampleAttribs"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesSampleAttribs.PNG"
></img
></chart
></example
></li
><li
>We are done editing the rule. You can save the file.</li
></ol
><p
>In brief what this rule does is set up an action to take place when a word is processed by the <object
type="tTool"
>Apertium</object
> engine that has the “n” tag. (Every word coming from <object
type="tFlexx"
></object
> has the word’s grammatical category in the form of a tag. It’s always the first tag.)</p
><p
>The <object
type="tRuleElemInXXE"
>action</object
> that we execute is to strip off any affixes from the word. This is accomplished by outputting the word itself -- the “lem” part and the grammatical category -- anything that matches a tag specified by in the “a_gram_cat” attribute. No other tags (affixes) are explicitly outputted. The <object
type="tRuleElemInXXE"
>target lang.</object
> attribute of the <object
type="tRuleElemInXXE"
>clip</object
> elements in <exampleRef
letter="xRulesSampleNounRule"
num="xRulesSampleNounRule"
></exampleRef
> above is selected so the target word that corresponds to the input source word is outputted.</p
><p
>See <sectionRef
sec="sTransferTutorial"
showTitle="full"
textBefore="plural"
></sectionRef
> and <sectionRef
sec="sTransferRuleHowTos"
showTitle="full"
></sectionRef
> for more information on transfer rules. The authoritative reference document for transfer rules is found in section 3.5 and appendix 3 of <citation
ref="rApertium"
></citation
>. <comment
>intro info here (not sure if would be helpful) http://wiki.apertium.org/wiki/Apertium_New_Language_Pair_HOWTO#Transfer_rules</comment
></p
><p
><comment
>Maybe reference to where to find other transfer rules</comment
></p
><p
><comment
>Run Set up Gramm Categories Tool at some early stage</comment
></p
></section2
><section2
id="sRunModules"
><secTitle
>Run <object
type="tFlextrans"
></object
> Modules</secTitle
><ol
><li
>In <object
type="tFlexxTools"
></object
>, click on the <img
cssSpecial="Width:5%"
src="Images/CollectionsBut.PNG"
></img
> button.</li
><li
>Double-click on <object
type="tCollection"
>FLExTrans All Steps</object
> in the list and you’ll see <exampleRef
letter="xFirstStart"
num="xFirstStart"
></exampleRef
>.</li
><li
>Click on the <img
cssSpecial="Width:7%"
src="Images/RunAllModifyBut.PNG"
></img
> button to run all the modules. Click OK on the message box that comes up to confirm you want to change <object
type="tFlexx"
></object
> data. You’ll see the modules run and see various bits of output.</li
></ol
><p
>You can see the results by opening the target <object
type="tFlexx"
></object
> project. (You may have to do a “refresh” to see the new text.)</p
><p
><comment
>Advanced info.: </comment
></p
><p
><comment
>Results can also be seen in the Output folder.</comment
></p
></section2
></section1
><section1
id="sLinker"
><secTitle
>The <object
type="tSenseLinker"
></object
></secTitle
><p
>The <object
type="tSenseLinker"
></object
> is a tool for linking source senses to target senses. The tool looks through the text specified in the configuration file and lists every sense that was analyzed in that text in order. Here’s sample screen shot of the <object
type="tSenseLinker"
></object
>: <comment
>Need a new image and explain new stuff like, hiding proper nouns, and the search box!</comment
></p
><example
num="xLinkerToolShot"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial=" height:60%"
src="Images/SenseLinkerCapture.png"
></img
></chart
></example
><p
>Here’s a key to the color coding:</p
><table
border="1"
><tr
><th
>Color</th
><th
></th
></tr
><tr
><td
>White</td
><td
>Source sense has been linked to a target sense.</td
></tr
><tr
><td
>Red</td
><td
>Source sense has not been linked to a target sense.</td
></tr
><tr
><td
>Light Blue</td
><td
>A target sense has been suggested for this source sense through a partial match of the glosses.</td
></tr
><tr
><td
>Blue</td
><td
>A target sense has been suggested for this source sense through an exact match of the glosses.</td
></tr
><tr
><td
>Green</td
><td
>The target sense has been set or changed for this source sense.</td
></tr
><tr
><td
>Red Text</td
><td
>There is a mismatch of grammatical category even though the glosses match.</td
></tr
></table
><p
>For suggested sense links (colored in blue), if you want to link them, simply check the check box in the Link It column. To link a source sense with a target sense where there is no suggestion or to change an existing link, you need to do two things. First, select the target sense that you want to link to in the drop down list of All Target Senses then go to the Target Head Word column for the source sense in question and double-click there. The target sense information should appear with a green background color.</p
><p
>If you only want to see the senses that need to be linked, check the box that says Show Only Unlinked.</p
></section1
><section1
id="sRuleTester"
><secTitle
>The <object
type="tLiveRuleTester"
></object
></secTitle
><p
>The <object
type="tLiveRuleTester"
></object
> is a tool that allows you to test source words or sentences live against transfer rules. This tool is especially helpful for finding out why transfer rules not are doing what you expect them to do. You can zero in on the problem by selecting just one source word and applying the pertinent transfer rule. In this way you don’t have to run the whole system against the whole text file and all transfer rules. Here’s sample screen shot of the <object
type="tLiveRuleTester"
></object
>:</p
><example
num="xTesterImage"
><chart
><img
XeLaTeXSpecial="scaled='500'"
cssSpecial=" height:50%"
src="Images/LiveRuleTester.png"
></img
></chart
></example
><section2
id="sTesterQuickGuide"
><secTitle
>Quick Guide</secTitle
><p
>Here’s a quick guide on using the Live Rule Tester Tool.</p
><ol
><li
>First you want to choose something from your source text that you want to test. When you first run the tool, the words of the first sentence are shown both in the drop down list at the top and in the peach-colored area. You can check one or more words and when you do the <genericRef
gref="gDataStream"
>data stream format</genericRef
> of the words is shown in the blue-colored area. You can quickly select a whole sentence, by clicking on the Select Sentences tab and clicking on the sentence you want.</li
><li
>Next select which rule or rules you want to run against the words you selected. Check the check boxes in the purple area as appropriate. Check them all with the <object
type="tButton"
>Select All</object
> button. Uncheck them all with the <object
type="tButton"
>Unselect All</object
> button. Move a rule up or down by clicking on it and clicking the up or down arrow buttons.</li
><li
>Now you are ready to test. Click the <object
type="tButton"
>Transfer</object
> button and you will process the selected words. You will see the results in <genericRef
gref="gDataStream"
>data stream format</genericRef
> in the green-colored area.</li
><li
>Check the yellow Information box. It will show which words were matched for the rules that were executed.</li
><li
>Now you are ready to synthesize. Click the <object
type="tButton"
>Synthesize</object
> button and you will synthesize the target text lexical entries in the green-colored area into target words in the salmon-colored area.</li
><li
>Use the <object
type="tButton"
>Add to Testbed</object
> button to add the input words and synthesized result to the "Testbed". This is essentially a database of expected results for a certain inputs. In another part of <object
type="tFlextrans"
></object
> you can run the Testbed to see if you are still getting the results you expect.</li
></ol
></section2
><section2
id="sTesterOther"
><secTitle
>Other Parts of the Tool</secTitle
><p
>By default the transfer rules file, the bilingual lexicon file and the source text are loaded according to the configuration file. The transfer rules file and the bilingual lexicon file can be changed if desired by clicking the corresponding <object
type="tButton"
>Browse</object
> buttons.</p
><p
>In this version of the tool, you can’t change the Source Text Name. You will have to edit the configuration file, change the SourceTextName value and re-run the tool.</p
><p
>You may have noticed that there is a Manual Entry tab for the source text words. You can enter words (technically word-senses) directly in plain text data stream format<endnoteRef
note="nRawDataStream"
></endnoteRef
>. This might be useful if you want to test a word-sense that isn’t in a given text.</p
><p
>The <object
type="tButton"
>Interchunk</object
> and <object
type="tButton"
>Postchunk</object
> tabs are for use in testing rules using the advanced <object
type="tTool"
>Apertium</object
> transfer engine.</p
><p
>You can’t edit the transfer rules in the <object
type="tLiveRuleTester"
></object
> and even when you change the order of the rules in the tool that doesn’t change your transfer rules file. Make your changes in a separate editor. To reload the transfer rules after you have changed them, click on the <object
type="tButton"
>Refresh Rules</object
> button.</p
><p
>If you change the target lexicon, click the <object
type="tButton"
>Refresh Target Lexicon</object
> button to reload it so that upon synthesis, <object
type="tFlextrans"
></object
> uses the changed lexicon.</p
><p
>There is a check box that says <object
type="tButton"
>Add multiple words to the testbed word by word</object
>. Use this when you want to add multiple one-word translations to the testbed in batch. This is useful, for example, if you have a "sentence" that runs through a paradigm. When you click <object
type="tButton"
>Add to Testbed</object
>, <object
type="tFlextrans"
></object
> will add each individual word and its corresponding synthesis to the testbed in one go. Each pair will be its own test.</p
></section2
></section1
><section1
id="sViewSrcTgt"
><secTitle
>The <object
type="tViewSrcTgt"
></object
></secTitle
><p
>The <object
type="tViewSrcTgt"
></object
> is a tool that allows you to view the <object
type="tTool"
>Apertium</object
> source or target files in an easy-to-read manner. You may not need to examine the <object
type="tTool"
>Apertium</object
> files <object
type="tFilename"
>source_text.aper</object
> or <object
type="tFilename"
>target_text.aper</object
> very often, but sometimes you may find it useful to see what got extracted from the source <object
type="tFlexx"
></object
> project into <object
type="tFilename"
>source_text.aper</object
> or to see what the transfer rules produced after running the <object
type="tModule"
>RunApertium</object
> module in the form of <object
type="tFilename"
>target_text.aper</object
>. Run this tool to see the contents of these files. <exampleRef
letter="xViewSrcTgt"
num="xViewSrcTgt"
></exampleRef
> shows what the tool looks like. The actual file contents look like <exampleRef
letter="xDataStream"
num="xDataStream"
></exampleRef
>.</p
><example
num="xViewSrcTgt"
><chart
><img
cssSpecial=" height:60%"
src="Images/SourceTargetViewer.png"
></img
></chart
></example
><example
num="xDataStream"
><chart
><img
src="Images/DataStreamFormat.PNG"
></img
></chart
></example
><p
>You have the options of changing the font, increasing the zoom level, displaying the text right-to-left or opening a similar view in the default web browser. If you click on the <object
type="tBold"
>Target</object
> button, you will see the contents of <object
type="tFilename"
>target_text.aper</object
>.</p
></section1
><section1
id="sSetupGramCat"
><secTitle
>The <object
type="tTool"
>Set Up Transfer Rule Grammatical Categories Tool</object
></secTitle
><p
>The <object
type="tTool"
>Set Up Transfer Rule Grammatical Categories Tool</object
> is a tool that will put the necessary attribute values for grammatical categories into your transfer rules file. Every transfer rule will likely need to reference the grammatical category of a word either in the source or target language. The initial transfer rules file that comes with <object
type="tFlextrans"
></object
> has just a few sample grammatical categories. This tool will take the categories that are in the bilingual lexicon file and insert them as tags under the specific attribute called <object
type="tCourier"
>a_gram_cat</object
> in the transfer rules file. The list of grammatical categories will be a complete list of all the unique categories in both the source and target <object
type="tFlexx"
></object
> projects.</p
><p
>You should only need to run this tool one time at the beginning of the <object
type="tFlextrans"
></object
> project. If new grammatical categories get added to either <object
type="tFlexx"
></object
> project, you could delete the <object
type="tCourier"
>a_gram_cat</object
> attribute and run this tool again to get an updated list in your transfer rules file.</p
><p
><exampleRef
letter="xSetupGramCat"
num="xSetupGramCat"
></exampleRef
> shows what the <object
type="tCourier"
>a_gram_cat</object
> attribute looks like after running this tool.</p
><example
num="xSetupGramCat"
><chart
><img
src="Images/SetupGramCat.PNG"
></img
></chart
></example
></section1
><section1
id="sTransferTutorial"
><secTitle
>A Tutorial on Writing Transfer Rules<endnote
id="nReproducing"
><p
>For this tutorial I am basically reproducing the <object
type="tTool"
>Apertium</object
> article <link
href="http://wiki.apertium.org/wiki/A_long_introduction_to_transfer_rules"
>A long introduction to transfer rules</link
>. I am mainly modifying it to show the <object
type="tXMLmindXMLEditor"
></object
> method of editing the transfer rules, but also the <object
type="tFlextrans"
></object
> process is assumed instead of the <object
type="tTool"
>Apertium</object
> process.</p
></endnote
></secTitle
><p
>Writing transfer rules is not as tricky as it might seem. People generally understand the basic concepts, but they sometimes struggle with the formalism. Maybe one of the reasons people struggle is that the formalism mixes declarative and procedural statements. This tutorial should help you get used to writing transfer rules.</p
><p
><comment
>Add a section on how spaces and periods are treated in various places.</comment
></p
><section2
id="sOverview"
><secTitle
>Overview</secTitle
><p
>Here’s a brief overview:</p
><section3
id="sFormalities"
><secTitle
>Some Formalities</secTitle
><p
>Before starting, it is important to get an idea of what we can’t do, before explaining what we can.</p
><ul
><li
>There are no recursive rules. Rules match fixed-length patterns. There is no optionality at the level of words. There is no way of saying one or more, it’s just one.</li
><li
>Rules contain both declarative parts and procedural parts. You can’t just expect to say what you want or how you want to do it. You need to do both -- but in different places (but it’s quite intuitive).</li
><li
>Patterns match only on the source side, not on the target side.</li
><li
>The transfer process has no access to the information in the target language dictionary. This means that if the transfer needs some information about the available forms of a particular word, e.g. if it is only singular, or only plural, then this information needs to go in the bilingual dictionary.</li
></ul
></section3
><section3
id="sApproach"
><secTitle
>Approaching the Process of Writing Transfer Rules</secTitle
><p
>Think bottom up, not top down. Start with a question like “What is the simplest and best equivalent for dative in a language which does not have dative?” not “How can I change SOV order to SVO order?”</p
></section3
><section3
id="sLexicalStruct"
><secTitle
>Lexical Transfer and Structural Transfer</secTitle
><p
>We don’t want to confuse the roles of lexical transfer and structural transfer. There is a grey area between the two, but there are also big parts that don’t overlap.</p
><ul
><li
><object
type="tBold"
>Lexical transfer</object
> (the <object
type="tFilename"
>bilingual.dix</object
> file -- produced by the <object
type="tSenseLinker"
></object
> and the <object
type="tModule"
>Extract Bilingual Lexicon</object
> module)<ul
><li
>Nearly always gives translations between words, not tags.</li
><li
>Can add or change tags, on a per-sense basis.</li
><li
>Doesn’t do reordering.</li
><li
>Can be used to give a head’s up to the structural transfer to draw attention to missing features, or features that cannot be decided on a no-context basis.</li
></ul
></li
><li
><object
type="tBold"
>Structural transfer</object
> (the <object
type="tFilename"
>transfer_rules.t1x</object
> file -- edited with <object
type="tXMLmindXMLEditor"
></object
>)<ul
><li
>Rarely gives translations between single words.</li
><li
>Often adds or changes tags on a per-category (groups of words) basis.</li
><li
>Can change the order of words.</li
></ul
></li
></ul
><p
>A rule-of-thumb is, if the rule applies to all words in a category, it probably wants to be treated in the structural transfer; if it applies to just part of those words, then maybe it needs to be dealt with in the lexical transfer.</p
><p
>Lexical transfer for a three word text looks like <exampleRef
letter="xLexXfer"
num="xLexXfer"
></exampleRef
>. In other words, the bilingual dictionary maps a source word to target word. In <object
type="tFlextrans"
></object
> you don’t normally need to examine the bilingual dictionary, but conceptually it looks like this. Open the <object
type="tFilename"
>bilingual.dix</object
> in the XML Mind editor for the details.</p
><example
num="xLexXfer"
><single
><langData
lang="lVernacular"
>slword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>somecat</object
> -&gt; tlword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>somecat</object
> <br
></br
>slword1<object
type="tSubscript"
>2.1</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>blah</object
> -&gt; tlword3<object
type="tSubscript"
>1.2</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>foo</object
><br
></br
>slword3<object
type="tSubscript"
>3.1</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>blah</object
> -&gt; tlword2<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>GD</object
></langData
></single
></example
><p
>The output of the structural transfer would look like <exampleRef
letter="xStrXfer"
num="xStrXfer"
></exampleRef
>.</p
><example
num="xStrXfer"
><single
><langData
lang="lVernacular"
>tlword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>somecat</object
> tlword3<object
type="tSubscript"
>1.2</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>foo</object
> tlword2<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>somecat</object
> <object
type="tluAffix"
>GD</object
></langData
></single
></example
><p
>When you are in the structural transfer stage, you have access to both the source and target sides.</p
><section4
id="sLexTransProc"
><secTitle
>How Lexical Transfer is Processed</secTitle
><p
>This isn’t critical information that you have to know, but gives insight into what’s going on. Feel free to skip this section.</p
><p
>Given an input lexical unit shown in <exampleRef
letter="xInputLexUnit"
num="xInputLexUnit"
></exampleRef
>:</p
><example
num="xInputLexUnit"
><single
><langData
lang="lVernacular"
>slword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cat1</object
> <object
type="tluAffix"
>aff2</object
> <object
type="tluAffix"
>aff3</object
></langData
></single
></example
><p
>If we have the following in the bilingual dictionary:</p
><example
num="xBiLingEntry"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:75%"
src="Images/RulesTutSampBilEntry.PNG"
></img
></chart
></example
><p
>Which gives the following mapping in terms of lexical units:</p
><example
num="xMappingSample"
><single
><langData
lang="lVernacular"
>slword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cat1</object
> <object
type="tluAffix"
>aff2</object
> -&gt; tlword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cat1</object
></langData
></single
></example
><p
>We will get this target-language output from the lexical-transfer module:</p
><example
num="xLexXferResult"
><single
><langData
lang="lVernacular"
>tlword<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cat1</object
> <object
type="tluAffix"
>aff3</object
></langData
></single
></example
><p
>Note that the target-language lexical form, as defined in the bilingual dictionary entry in <exampleRef
letter="xBiLingEntry"
num="xBiLingEntry"
></exampleRef
>, is produced by replacing two tags on the source side (i.e. <langData
lang="lVernacular"
>cat1 aff2</langData
>) with one tag on the target side (i.e. <langData
lang="lVernacular"
>cat1</langData
>).</p
><p
>Important: any source language tags not matched in the bilingual dictionary entry are copied into the output on the target language side. In our example, <langData
lang="lVernacular"
><object
type="tluAffix"
>aff3</object
></langData
> in <exampleRef
letter="xInputLexUnit"
num="xInputLexUnit"
></exampleRef
> gets copied to the final output in <exampleRef
letter="xLexXferResult"
num="xLexXferResult"
></exampleRef
>.</p
></section4
></section3
><section3
id="sPrelim"
><secTitle
>Some Preliminaries</secTitle
><p
>The transfer rule file is written in an XML format and in <object
type="tFlextrans"
></object
> it is named <object
type="tFilename"
>transfer_rules.t1x</object
><endnote
id="nT1X"
><p
>The 1 in .t1x stands for the first structural transfer pass. This is the only file we worry about when doing a shallow-transfer system. For advanced-transfer, you use three rule files, and the extensions .t2x and .t3x are also used.</p
></endnote
>. We could do all the editing of the transfer rules in a text editor, but by using the structured editor <object
type="tXMLmindXMLEditor"
></object
> we not only get a graphical user interface, but also verification that the rule file we are writing is valid. In fact the <object
type="tXMLmindXMLEditor"
></object
> and the add-ons for <object
type="tFlextrans"
></object
> make it hard to write an invalid rule file.</p
></section3
><section3
id="sFileOverview"
><secTitle
>Overview of a Transfer File</secTitle
><p
>It’s hard to give a step-by-step overview of what a transfer file looks like because there is quite a lot of obligatory parts that need to go into even the most basic file. But, it’s important to get a general view before we go into the details. Here is an example in which I’m deliberately not going to use linguistic names for the different parts to try and avoid assumptions.</p
><example
num="xOverviewRuleFile"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:50%;"
src="Images/RulesTutOverview.PNG"
></img
></chart
></example
><p
>You should see this same thing when you open the file <object
type="tFilename"
>transfer_rules.t1x</object
> (<object
type="tFoldername"
>FLExTrans Documentation\Transfer Rules Tutorial</object
> folder) in the <object
type="tXMLmindXMLEditor"
></object
>. (Expand all the elements.)</p
><p
>The transfer file is divided into two main parts: a declaration section and a rules section. The rules section uses information from the declaration section. In fact, every kind of reference you make in the rules section, you have to declare in the declaration section. The rules section is clearly denoted by the element <object
type="tRuleElemInXXE"
>Rules</object
>. All of the elements above <object
type="tRuleElemInXXE"
>Rules</object
> are part of the declaration section. In <exampleRef
letter="xOverviewRuleFile"
num="xOverviewRuleFile"
></exampleRef
> a minimal amount of declarations are shown, namely the <object
type="tRuleElemInXXE"
>Categories</object
>, <object
type="tRuleElemInXXE"
>Attributes</object
>, and <object
type="tRuleElemInXXE"
>Variables</object
> elements. (The elements <object
type="tRuleElemInXXE"
>Lists</object
> and <object
type="tRuleElemInXXE"
>Macros</object
> are not shown.)</p
><p
>Rules have two main parts: the pattern definition and the actions to be carried out.</p
><p
>The <object
type="tRuleElemInXXE"
>pattern</object
> element is what determines if <object
type="tTool"
>Apertium</object
> runs the rule or not. If the input word or words match the pattern, <object
type="tTool"
>Apertium</object
> will run the rule. The thing that goes in the <object
type="tRuleElemInXXE"
>item</object
> sub-element of the <object
type="tRuleElemInXXE"
>pattern</object
> element is a list of one or more categories (from the declaration section) you want to match.</p
><p
>The <object
type="tRuleElemInXXE"
>action</object
> element contains the steps you want to perform in the rule, generally ending with an <object
type="tRuleElemInXXE"
>output</object
> element where you output lexical units into the data stream. Note how declared attributes are used in the <object
type="tRuleElemInXXE"
>action</object
> element. Categories and attributes are discussed more below.</p
></section3
><section3
id="sRulesApplied"
><secTitle
>How Rules are Applied</secTitle
><p
>Rules are applied when a pattern is matched in the source language input data stream. Which patterns are matched in which order goes like this: the longest patterns are attempted first and then successive shorter patterns are attempted. When there is more than one pattern of the same length, the pattern that comes first in the file is attempted first followed by the rest in order.</p
><p
>Patterns do not overlap. Once a pattern is matched, the matched words are processed and not considered again for any other patterns. In other words, the source language words are processed sequentially in chunks. Cf. <sectionRef
sec="sPatternMatch"
showTitle="full"
></sectionRef
>.</p
></section3
></section2
><section2
id="sPracticalEx"
><secTitle
>Practical Example</secTitle
><example
num="xCroatEngTable"
><table
border="1"
><tr
><th
>Input:</th
><td
>Otišla si</td
><td
>tiho</td
><td
>i</td
><td
>bez</td
><td
>pozdrava</td
></tr
><tr
><th
>Output:</th
><td
>You left</td
><td
>quietly</td
><td
>and</td
><td
>without</td
><td
>a word</td
></tr
></table
></example
><p
>Let’s do an exercise where the goal is to turn a sentence in Croatian into English. The input and desired output is shown in <exampleRef
letter="xCroatEngTable"
num="xCroatEngTable"
></exampleRef
>.</p
><section3
id="sTutSetup"
><secTitle
>Getting Set Up</secTitle
><ol
><li
>There are two <object
type="tFlexx"
></object
> projects already set up that we are going to use. You will find them in the <object
type="tFoldername"
>FLExTrans Documentation\Transfer Rules Tutorial</object
> folder. They are called <object
type="tFilename"
>Croatian-FLExTrans-Sample.fwbackup</object
> and <object
type="tFilename"
>English-FLExTrans-Sample.fwbackup</object
>. Double-click on them one by one to restore them into <object
type="tFlexx"
></object
>.</li
><li
>Now close both <object
type="tFlexx"
></object
> projects,</li
><li
>We will be writing new transfer rules so let’s rename the current rule file.<ol
><li
>Go to the top-level folder and rename the file <object
type="tFilename"
>transfer_rules.t1x</object
> to <object
type="tFilename"
>transfer_rules_saved.t1x</object
>.</li
><li
>Go to the <object
type="tFoldername"
>FLExTrans Documentation\Transfer Rules Tutorial</object
> folder again and copy the file <object
type="tFilename"
>transfer_rules.t1x</object
> to the top-level folder.</li
><li
>Open <object
type="tFilename"
>transfer_rules.t1x</object
> in the <object
type="tXMLmindXMLEditor"
></object
>.</li
></ol
></li
><li
>We will be changing the configuration file so let’s rename the current one.<ol
><li
>Go to the top-level folder and rename the file <object
type="tFilename"
>FlexTrans.config</object
> to <object
type="tFilename"
>FlexTrans_saved.config</object
>.</li
><li
>Go to the <object
type="tFoldername"
>FLExTrans Documentation\Transfer Rules Tutorial</object
> folder again and copy the file <object
type="tFilename"
>FlexTrans.config</object
> to the top-level folder.</li
></ol
></li
><li
>Start <object
type="tFlexxTools"
></object
>. See <appendixRef
app="sStartFlextools"
></appendixRef
> for step-by-step instructions.</li
><li
>Make sure the <object
type="tCollection"
>FlexTrans All Steps</object
> collection is active.</li
></ol
></section3
><section3
id="sLexicalTransfer"
><secTitle
>Lexical Transfer</secTitle
><p
>For the purposes of this example, we are going to use some “pre-prepared” data. We have a Croatian text that is already analyzed and we have small Croatian and English lexicons with all of the entries and senses that we need.</p
><p
>Let’s see what our input and output looks like initially if we run the system. Our input of course, according to <exampleRef
letter="xCroatEngTable"
num="xCroatEngTable"
></exampleRef
> is: <langData
lang="hr"
>Otišla si tiho i bez pozdrava.</langData
></p
><ol
><li
>Bring up the <object
type="tFlexxTools"
></object
> app.</li
><li
>Click the <object
type="tButton"
>Database</object
> button, select <object
type="tBoldItalic"
>Croatian-FLExTrans-Sample</object
> and type the Enter key.</li
><li
>Click the <object
type="tButton"
>Run All (Modify)</object
> button to run all the <object
type="tFlextrans"
></object
> modules. (Click Yes when prompted to make changes.)</li
><li
>Open the <object
type="tBold"
>English-FLExTrans-Sample</object
> <object
type="tFlexx"
></object
> project.</li
><li
>In the Texts and Words view, refresh the screen and click on the text titled “Left Behind”.</li
></ol
><p
>You should see:</p
><example
num="xOutputInitial"
><single
><gloss
lang="lGloss"
>Leavepfvptcp f sg beprssg2 quietly and without wordgen sg</gloss
></single
></example
><p
>Clearly we have some work to do, but at least three words look good. <exampleRef
letter="xOutputInitial"
num="xOutputInitial"
></exampleRef
> is what we get using straight lexical transfer. In other words, English word-senses are substituted for Croatian word-senses. The sample transfer rule we are using (shown in <exampleRef
letter="xOverviewRuleFile"
num="xOverviewRuleFile"
></exampleRef
>) is having no influence during the transfer process.</p
><p
>Let’s look at the input and output in data stream format.</p
><example
num="xCroatEngDataStreamTable"
><table
border="1"
><tr
><th
>Input:<endnote
id="nInputFile"
><p
>You would see this if you use the <object
type="tModule"
>View Source/Target Apertium File Tool</object
>. It is the friendly view of the file <object
type="tFilename"
>source_text.aper</object
> in the <object
type="tFoldername"
>Output</object
> folder. The actual content looks like this: <langData
lang="lVernacular"
>^Otići1.1&lt;v&gt;&lt;pfv&gt;&lt;ptcp_f_sg&gt;$ ^biti1.1&lt;cop&gt;&lt;prs&gt;&lt;sg&gt;&lt;2&gt;$ ^tiho1.1&lt;adv&gt;$ ^i1.1&lt;coordconn&gt;$ ^bez1.1&lt;prep&gt;$ ^pozdrav1.1&lt;n&gt;&lt;gen_sg&gt;$</langData
></p
></endnote
></th
><td
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
></langData
></td
><td
><langData
lang="lVernacular"
>biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs</object
> <object
type="tluAffix"
>sg</object
> <object
type="tluAffix"
>2</object
></langData
></td
><td
><langData
lang="lVernacular"
>tiho<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>adv</object
></langData
></td
><td
><langData
lang="lVernacular"
>i<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>coordconn</object
></langData
></td
><td
><langData
lang="lVernacular"
>bez<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>prep</object
></langData
></td
><td
><langData
lang="lVernacular"
>pozdrav<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>gen_sg</object
> </langData
></td
></tr
><tr
><th
>Output:<endnote
id="nOutputFile"
><p
>You would see this if you use the <object
type="tModule"
>View Source/Target Apertium File Tool</object
> and click the <object
type="tButton"
>Target</object
> button. It is the friendly view of the file <object
type="tFilename"
>target_text.aper</object
> in the <object
type="tFoldername"
>Output</object
> folder. The actual content looks like this: <langData
lang="lVernacular"
>^Leave1.1&lt;v&gt;&lt;pfv&gt;&lt;ptcp_f_sg&gt;$ ^be1.1&lt;cop&gt;&lt;prs&gt;&lt;sg&gt;&lt;2&gt;$ ^quietly1.1&lt;adv&gt;$ ^and1.1&lt;coordconn&gt;$ ^without1.1&lt;prep&gt;$ ^word1.1&lt;n&gt;&lt;gen_sg&gt;$</langData
></p
></endnote
></th
><td
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
> </langData
></td
><td
><langData
lang="lVernacular"
>be<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs</object
> <object
type="tluAffix"
>sg</object
> <object
type="tluAffix"
>2</object
> </langData
></td
><td
><langData
lang="lVernacular"
>quietly<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>adv</object
> </langData
></td
><td
><langData
lang="lVernacular"
>and<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>coordconn</object
> </langData
></td
><td
><langData
lang="lVernacular"
>without<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>prep</object
> </langData
></td
><td
><langData
lang="lVernacular"
>word<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>gen_sg</object
> </langData
></td
></tr
></table
></example
></section3
><section3
id="sThinking"
><secTitle
>Thinking it Through</secTitle
><p
>Let’s think about what changes we need to make in order to convert the output shown in <exampleRef
letter="xCroatEngDataStreamTable"
num="xCroatEngDataStreamTable"
></exampleRef
> into an adequate form for target language synthesis. NB: If we want to change information, it’s a procedure; if we want to output information or not output information, it’s a declaration.</p
><section4
id="sProc"
><secTitle
>Procedures</secTitle
><ol
><li
>If the source language grammatical category tag is<langData
lang="lVernacular"
> <object
type="tluAffix"
>ptcp_f_sg</object
></langData
>, change the target language tag to <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
><endnote
id="nPastSuf"
><p
><langData
lang="lVernacular"
> <object
type="tluAffix"
>pst</object
></langData
> corresponds to the past suffix in the English <object
type="tFlexx"
></object
> project (and also the past tense feature).</p
></endnote
></li
></ol
></section4
><section4
id="sDecl"
><secTitle
>Declarations</secTitle
><ol
><li
>Output a subject pronoun which takes its person and number information from the auxiliary verb.</li
><li
>Output the main verb with information on category and tense (but not aspect).</li
><li
>Do not output the auxiliary verb <langData
lang="hr"
>biti</langData
>, “be”.</li
><li
>Output nouns with their grammatical category (but not number or case).</li
></ol
></section4
><section4
id="sWorkOrder"
><secTitle
>Work Order</secTitle
><p
>So, what order do we do these in? Well it doesn’t really matter. An experienced <object
type="tFlextrans"
></object
> linguist would probably do it in two steps, but for pedagogical purposes, we’re going to split it up into five steps:</p
><ul
><li
>First, we’re going to write a rule which matches the participle and auxiliary construction and outputs only the main verb (declarations: 2 &amp; 3). <ul
><li
>Define the categories of “ptcp_f_sg” and “biti”.</li
></ul
></li
><li
>Second, we’re going to edit that rule to change the source language tag from<langData
lang="lVernacular"
> <object
type="tluAffix"
>ptcp_f_sg</object
></langData
> to<langData
lang="lVernacular"
> <object
type="tluAffix"
>pst</object
></langData
> (procedure: 1).<ul
><li
>Define the attribute of “tense”.</li
></ul
></li
><li
>Third, we’re going to edit the same rule to not output aspect (declaration: 2).<ul
><li
>Define the attribute for grammatical category and add the tag for “verb”.</li
></ul
></li
><li
>Fourth, we’re going to edit the same rule to output a subject pronoun before the verb (declaration: 1).<ul
><li
>Define the attributes of “person” and “number”.</li
></ul
></li
><li
>Fifth, we’re going to write a new rule which matches the noun construction and output only the grammatical category (declaration: 4) <ul
><li
>Define the category of “noun”.</li
><li
>Add the tag for nouns to the grammatical category attribute.</li
></ul
></li
></ul
></section4
><section4
id="sCheatsheet"
><secTitle
>Cheat Sheet</secTitle
><p
>Here is what the input and output data stream of each of the above steps will look like:</p
><example
num="xCheatsheet"
><table
border="1"
><tr
><th
>Step</th
><th
>Input</th
><th
>Output</th
></tr
><tr
><td
>1</td
><td
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></td
><td
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
></langData
></td
></tr
><tr
><td
>2</td
><td
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></td
><td
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>pst</object
> </langData
></td
></tr
><tr
><td
>3</td
><td
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></td
><td
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pst</object
> </langData
></td
></tr
><tr
><td
>4</td
><td
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv</object
> <object
type="tluAffix"
>ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></td
><td
><langData
lang="lVernacular"
>Propers<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>pro</object
> <object
type="tluAffix"
>nom</object
> <object
type="tluAffix"
>2</object
> <object
type="tluAffix"
>sg</object
> leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pst</object
> </langData
></td
></tr
><tr
><td
>5</td
><td
><langData
lang="lVernacular"
>pozdrav<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>gen_sg</object
></langData
></td
><td
><langData
lang="lVernacular"
>word<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
></langData
></td
></tr
></table
></example
></section4
></section3
><section3
id="sImplementation"
><secTitle
>Implementation</secTitle
><p
>Let’s see what data stream output we get for the first two words right now. To do this we will use the <object
type="tLiveRuleTester"
></object
> which is a great tool for applying a single rule to one or more words and checking the result. See <sectionRef
sec="sRuleTester"
showTitle="numberOnly"
textBefore="singular"
></sectionRef
>.</p
><ol
><li
>Close the <object
type="tBold"
>English-FLExTrans-Sample</object
> <object
type="tFlexx"
></object
> project.</li
><li
>Bring up the <object
type="tFlexxTools"
></object
> app.</li
><li
>Click the <object
type="tButton"
>Collections</object
> button.</li
><li
>Double-click on the <object
type="tCollection"
>FlexTrans Tools</object
> collection.</li
><li
>Select the <object
type="tModule"
>FLExTrans.Live Rule Tester Tool</object
> module.</li
><li
>Click on the <object
type="tButton"
>Run</object
> button.</li
><li
>Check the first two Croatian words.</li
><li
>Click on the <object
type="tButton"
>Transfer</object
> button.</li
></ol
><p
>Your <object
type="tLiveRuleTester"
></object
> should look like this:</p
><example
num="xTesterStep0"
><chart
><img
XeLaTeXSpecial="scaled='600'"
cssSpecial="Height:60%"
src="Images/RulesTutTesterStep0.PNG"
></img
></chart
></example
><p
>In the blue box we have the input data stream for the first two (checked) Croatian words:</p
><example
num="xStep0Source"
><single
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></single
></example
><p
>This matches what we have in the cheat sheet in <exampleRef
letter="xCheatsheet"
num="xCheatsheet"
></exampleRef
>.</p
><p
>In the green box we have the output data stream after the sample rule is applied.</p
><example
num="xStep0Target"
><single
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv ptcp_f_sg</object
> be<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></single
></example
><p
>Since we haven’t done anything, it doesn’t yet match our output goal for step one in the cheat sheet.</p
><section4
id="step1"
><secTitle
>Step 1</secTitle
><ol
><li
><p
>Define the categories we need in <object
type="tFilename"
>transfer_rules.t1x</object
>. Replace the dummy <object
type="tRuleElemInXXE"
>Categories</object
> element with:</p
><example
num="xCat1"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutCat1.PNG"
></img
></chart
></example
><p
>You may be wondering how you get a new <object
type="tRuleElemInXXE"
>category</object
> element inserted. It is straightforward:</p
><ol
><li
>Click on the word “category”. The whole element becomes outlined in a red rectangle.</li
><li
>Now either right-click and choose Insert After... or click on the <img
src="Images/ButInsertAfter.PNG"
></img
> button (upper right side) or press Ctrl-J.</li
><li
>At this point a list of elements to insert shows up in the upper right pane as shown in <exampleRef
letter="xInsertListCat"
num="xInsertListCat"
></exampleRef
>.<example
num="xInsertListCat"
><chart
><img
cssSpecial="Height:60%"
src="Images/InsertListCat.PNG"
></img
></chart
></example
></li
><li
>Choose in this case <object
type="tItalic"
>def-cat(category)</object
> since we only need one <object
type="tRuleElemInXXE"
>tags</object
> element. (By the way, this insert procedure will present only valid elements that can be inserted at this point in the rules file.)</li
></ol
><p
>Why do we need <langData
lang="lVernacular"
><object
type="tBold"
>.*</object
></langData
> in the <object
type="tRuleElemInXXE"
>tags</object
> elements? This is because of how the matching system for categories works. In the middle of tag sequences, a <langData
lang="lVernacular"
><object
type="tBold"
>*</object
></langData
> is counted as a single tag. At the end, it is counted as any sequence of tags. So, what we have is <langData
lang="lVernacular"
><object
type="tluGrammCat"
>v</object
></langData
> followed by any tag, followed by <langData
lang="lVernacular"
><object
type="tluAffix"
>ptcp_f_sg</object
></langData
>.</p
><p
>Note: we are using the convention of starting all categories with “<object
type="tBold"
>c_</object
>”.</p
></li
><li
>Edit the example rule and replace the pattern as shown. Also change the rule comment to “Past Construction”.<example
num="xPattern1"
><chart
><img
cssSpecial="Height:10%"
src="Images/RulesTutPattern1.PNG"
></img
></chart
></example
><p
><object
type="tItalic"
>Trick: Click in the pink area of the <object
type="tRuleElemInXXE"
>item</object
> element and press <object
type="tButton"
>F11</object
>. You will get a list of possible categories that can be used in this element. The list looks like</object
> <exampleRef
letter="xCatList"
num="xCatList"
></exampleRef
>.</p
><example
num="xCatList"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutCatList.PNG"
></img
></chart
></example
><p
>By using this pattern we will detect a participle followed by the auxiliary. Once detected, the rule will run.</p
><p
>Notice that the example rule as written outputs only the first among two lexical units as seen in <exampleRef
letter="xOutput1"
num="xOutput1"
></exampleRef
> (“item: 1” means the first item or word). We are not outputting the 2nd word. The result is that our <langData
lang="lVernacular"
>biti<object
type="tSubscript"
>1.1</object
></langData
> word will disappear.</p
><example
num="xOutput1"
><chart
></chart
></example
></li
><li
>Test it in the <object
type="tLiveRuleTester"
></object
>.<ol
><li
>Save the rule file.</li
><li
>Bring up the <object
type="tLiveRuleTester"
></object
>.</li
><li
>Click the <object
type="tButton"
>Refresh Rules</object
> button to reload the modified rule file.</li
><li
>Click on the <object
type="tButton"
>Transfer</object
> button. (This time you will notice some text in the yellow information box. This shows which rules matched which input words.)</li
></ol
><p
>The result is:</p
><example
num="xStep1Target"
><single
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv ptcp_f_sg</object
></langData
></single
></example
><p
>Great!</p
></li
></ol
></section4
><section4
id="step2"
><secTitle
>Step 2</secTitle
><ol
><li
>Replace the dummy <object
type="tRuleElemInXXE"
>attribute</object
> element with an attribute that gives possible values of the tense feature. <br
></br
><br
></br
>So, now that we’ve gotten rid of the verb “be”, we want to change the tag for tense from <langData
lang="lVernacular"
><object
type="tluAffix"
>ptcp_f_sg</object
></langData
> to <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
>. This will involve using a procedure statement, explicitly telling the transfer what we want to change. But before that, we need to define which possible values our feature can take. We do this with the <object
type="tRuleElemInXXE"
>attribute</object
> element. Let’s call it “<object
type="tBold"
>a_tense</object
>”. Note we are using the convention of starting all attributes with “<object
type="tBold"
>a_</object
>”.<br
></br
><br
></br
>Add the following under the <object
type="tRuleElemInXXE"
>Attributes</object
> element:<example
num="xAttrTense"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutAttrTense.PNG"
></img
></chart
></example
></li
><li
>Write a statement which changes the tense on the target language. This statement should go immediately after the <object
type="tRuleElemInXXE"
>action</object
> element and before the <object
type="tRuleElemInXXE"
>output</object
> element. Make sure you select the <object
type="tRuleElemInXXE"
>target lang.</object
> property.<example
num="xLet1"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLet1.PNG"
></img
></chart
></example
><object
type="tItalic"
>Trick: Click in the brown area of the <object
type="tRuleElemInXXE"
>part</object
> property and press <object
type="tButton"
>F11</object
>. You will get a list of possible attributes that can be used in this element. The list looks like</object
> <exampleRef
letter="xAttrList"
num="xAttrList"
></exampleRef
>.<example
num="xAttrList"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutAttrList.PNG"
></img
></chart
></example
>(Note: the statement in <exampleRef
letter="xLet1"
num="xLet1"
></exampleRef
> will always change the target language tag to <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
>, even if the input is not <langData
lang="lVernacular"
><object
type="tluAffix"
>ptcp_f_sg</object
></langData
>. This is good enough for our current example, but for a description of how conditional logic works, see <sectionRef
sec="sCondLogic"
showTitle="numberOnly"
textBefore="capitalizedSingular"
></sectionRef
>.<br
></br
><br
></br
></li
><li
>Now test it in the <object
type="tLiveRuleTester"
></object
>. (Don’t forget to refresh the rules first!)<br
></br
><p
>The result is:</p
><example
num="xStep2Target"
><single
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv pst</object
></langData
></single
></example
><p
>Excellent!</p
></li
></ol
></section4
><section4
id="step3"
><secTitle
>Step 3</secTitle
><p
>So far we have been outputting the whole target language lexical unit, as seen in <exampleRef
letter="xLexUnitWhole"
num="xLexUnitWhole"
></exampleRef
> below.</p
><p
>An important thing to know about lexical transfer is that any source language tags not matched in the bilingual dictionary are copied into the output on the target language side. In our case, <langData
lang="lVernacular"
><object
type="tluAffix"
>pfv pst</object
></langData
> are the tags that get copied from source to target because, in the bilingual dictionary (<object
type="tFilename"
>bilingual.dix</object
>), <langData
lang="lVernacular"
>otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
></langData
> maps to <langData
lang="lVernacular"
>leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
></langData
>. All we need is the <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
> tag; we don’t need the <langData
lang="lVernacular"
><object
type="tluAffix"
>pfv</object
></langData
> tag, so we need to declare that it should not be outputted.</p
><ol
><li
>Define the features that we want to output.<br
></br
><br
></br
>We have already defined the attribute “tense”: the only remaining tag we need to output is the grammatical category, i.e. <langData
lang="lVernacular"
><object
type="tluGrammCat"
>v</object
></langData
> meaning verb. So, make a new attribute element for grammatical category.<endnote
id="nUseSetUpTxfrRulGramCatTool"
><p
>It can be arduous to type in all the grammatical categories that you need for your transfer rules. That’s why there is the <object
type="tFlextrans"
></object
> tool called <object
type="tTool"
>Set Up Transfer Rule Grammatical Categories</object
>. This tool will insert all possible source and target categories for the <object
type="tBold"
>a_gram_cat</object
> attribute. See section <sectionRef
sec="sSetupGramCat"
></sectionRef
> for more details.</p
></endnote
><example
num="xAttrGramCat"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutAttrGramCat.PNG"
></img
></chart
></example
></li
><li
>Declare which attributes we want to output. <br
></br
><br
></br
>So, now that we’ve got our two attributes defined, let’s change our <object
type="tRuleElemInXXE"
>output</object
> statement: (You will have to open the <object
type="tRuleElemInXXE"
>output</object
> element with the plus sign.) <br
></br
><br
></br
>Where we previously had:<example
num="xLexUnitWhole"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLexUnitWhole.PNG"
></img
></chart
></example
>Replace it with:<example
num="xLexUnit3Clips"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLexUnit3Clips.PNG"
></img
></chart
></example
>The last two attributes we know, as we’ve just added them. The “lem” attribute is a predefined feature which corresponds to lemma, i.e. the part before the tags. In this example it would be <langData
lang="lVernacular"
>leave<object
type="tSubscript"
>1.1</object
></langData
>. There are other predefined features, but if you remember this one and “whole” which corresponds to the whole lexical unit, you have the main ones.<br
></br
><br
></br
></li
><li
>Now test it in the <object
type="tLiveRuleTester"
></object
>. (Don’t forget to refresh the rules first!)<br
></br
><p
>The result is:</p
><example
num="xStep3Target"
><single
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pst</object
></langData
></single
></example
><p
>Woo! What just happened was that we magically deleted the unwanted <langData
lang="lVernacular"
><object
type="tluAffix"
>pfv</object
></langData
> tag by not specifying that we wanted it. Tag deletion is thus not stated as tag deletion (tag → 0), but by not declaring it.</p
><p
>Now we should have a lexical form for “leave” which we can synthesize. Let’s give it a go. Click the <object
type="tButton"
>Synthesize</object
> button.</p
><p
>In the red box you should see:</p
><example
num="xOutputStep3a"
><single
><langData
lang="lVernacular"
>Left</langData
></single
></example
><p
>And if you click on the rest of the check boxes to select all of the Croatian words and click the <object
type="tButton"
>Transfer</object
> and <object
type="tButton"
>Synthesize</object
> buttons again you should see:</p
><example
num="xOutputStep3"
><single
><langData
lang="lVernacular"
>Left quietly and without wordgen sg</langData
></single
></example
><p
>This looks a lot better than our initial results in <exampleRef
letter="xOutputInitial"
num="xOutputInitial"
></exampleRef
>. The word <object
type="tItalic"
>Left</object
> is now there correctly. It’s beyond the scope of this exercise to explain in detail how the synthesis works in this case, but the tag <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
> matches the feature <langData
lang="lVernacular"
><object
type="tluAffix"
>pst</object
></langData
> on the variant form of the verb <object
type="tItalic"
>leave</object
>. See section <sectionRef
sec="sInflVariantTgt"
></sectionRef
> for more details.</p
><p
>We’re getting there, now let’s move on to the next step.</p
></li
></ol
></section4
><section4
id="step4"
><secTitle
>Step 4</secTitle
><p
>To recap, the input we’ve been working with is:</p
><example
num="xStep4Input"
><single
><langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv ptcp_f_sg</object
> biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
></langData
></single
></example
><p
>And our current output is:</p
><example
num="xStep4CurrentTarget"
><single
><langData
lang="lVernacular"
>Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pst</object
></langData
></single
></example
><p
>What we now need to do is take the information from the (not outputted) verb <object
type="tItalic"
>biti</object
> “be” and use it to output a personal pronoun before the verb. Remember that when we do not output something we are not deleting it. It is still there in the input, we are just choosing not to put it in the output.</p
><p
>The pronoun that we want to output looks like <exampleRef
letter="xStep4TargetGoal"
num="xStep4TargetGoal"
></exampleRef
>. If we get it in this form, it will synthesize into the word <object
type="tItalic"
>you</object
>.</p
><example
num="xStep4TargetGoal"
><single
><langData
lang="lVernacular"
>propers<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>pro</object
> <object
type="tluAffix"
>nom 2 sg</object
></langData
></single
></example
><p
><object
type="tUnderline"
>Important</object
>: We need to remember to output the <langData
lang="lVernacular"
>1.1</langData
> after the word and not just <langData
lang="lVernacular"
>propers</langData
>. Even though in the target <object
type="tFlexx"
></object
> project the lexeme form is <langData
lang="lVernacular"
>propers</langData
>, <object
type="tFlextrans"
></object
> automatically adds the homograph number (<langData
lang="lVernacular"
>1</langData
> because it’s the first and only homograph) and the sense number (<langData
lang="lVernacular"
>1</langData
> because it’s the first sense). If we mistakenly use <langData
lang="lVernacular"
>propers</langData
> instead of <langData
lang="lVernacular"
>propers1.1</langData
>, the word won’t synthesize because <object
type="tFlextrans"
></object
> won’t find <langData
lang="lVernacular"
>propers</langData
> in its internal dictionary. This use of <langData
lang="lVernacular"
>x.x</langData
> after the word helps <object
type="tFlextrans"
></object
> identify each unique sense in the dictionary.</p
><ol
><li
>Output a skeleton pronoun.<br
></br
><br
></br
>So, we need to take the person and number information from the verb “be”, and the rest we need to just declare to be outputted. Let’s start with outputting the string <langData
lang="lVernacular"
>propers<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>pro</object
> <object
type="tluAffix"
>nom</object
></langData
>; we won’t worry about the <langData
lang="lVernacular"
><object
type="tluAffix"
>2 sg</object
></langData
> tags yet.<br
></br
><br
></br
></li
><li
>Insert a new <object
type="tRuleElemInXXE"
>lexical unit</object
> before our current <object
type="tRuleElemInXXE"
>lexical unit</object
> element and make it look like <exampleRef
letter="xLexUnitPron"
num="xLexUnitPron"
></exampleRef
>.<br
></br
><p
>You can do an Insert Before... and choose <object
type="tItalic"
>lu(lexical_unit_lit-string)</object
> then click on the <object
type="tRuleElemInXXE"
>literal string</object
>, do an Insert After... and choose <object
type="tItalic"
>lit-tag(literal_tag)</object
>. The <object
type="tRuleElemInXXE"
>blank space</object
> element comes after and is <object
type="tUnderline"
>indented at the same level</object
> as <object
type="tRuleElemInXXE"
>lexical unit</object
>.</p
><example
num="xLexUnitPron"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLexUnitPron.PNG"
></img
></chart
></example
>The <object
type="tRuleElemInXXE"
>lexical unit</object
> statement means we are outputting a word<endnote
id="nLexUnit"
><p
>In our <object
type="tFilename"
>target_text.aper</object
> file it puts a <langData
lang="lVernacular"
>^</langData
> and <langData
lang="lVernacular"
>$</langData
> before and after the contents contained within it.</p
></endnote
>. The <object
type="tRuleElemInXXE"
>literal string</object
> element outputs the given string of characters, and the <object
type="tRuleElemInXXE"
>literal tag</object
> element outputs a tag sequence<endnote
id="nTagSeq"
><p
>In our <object
type="tFilename"
>target_text.aper</object
> file each tag starts with a <langData
lang="lVernacular"
>&lt;</langData
>, ends with a <langData
lang="lVernacular"
>&gt;.</langData
></p
></endnote
>. Multiple tags are separated by a period, so in this case we are outputting two tags: <langData
lang="lVernacular"
><object
type="tluGrammCat"
>pro</object
></langData
> and <langData
lang="lVernacular"
><object
type="tluAffix"
>nom</object
></langData
>. The <object
type="tRuleElemInXXE"
>blank space</object
> element outputs a single space character.<br
></br
><br
></br
></li
><li
>Define features for person and number. <br
></br
><br
></br
>The next step is to declare the features from the verb “be” to output. To do this we need to again define some attributes and their possible values. Add this:<example
num="xAttrNumPers"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutAttrNumPer.PNG"
></img
></chart
></example
></li
><li
>We then go back to our skeleton pronoun and add the missing features. So that it looks like <exampleRef
letter="xLexUnitPronPerNum"
num="xLexUnitPronPerNum"
></exampleRef
>.<br
></br
><p
>Click on the <object
type="tRuleElemInXXE"
>literal tag</object
> element and Insert After... and choose <object
type="tItalic"
>clip(clip_source_language)</object
>. Do this twice.</p
><example
num="xLexUnitPronPerNum"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLexUnitPronPerNum.PNG"
></img
></chart
></example
>Note that we are “clipping” (copying a part of a string which matches a pattern) from position 2, i.e. the verb “be”. To be clearer, the first clip statement in <exampleRef
letter="xLexUnitPronPerNum"
num="xLexUnitPronPerNum"
></exampleRef
> makes a copy of the part of the lexical unit in position 2, on the source language side, which matches one of the patterns defined in the attribute element “a_pers” (which can be either <langData
lang="lVernacular"
> 1</langData
>, <langData
lang="lVernacular"
> 2</langData
> or <langData
lang="lVernacular"
> 3</langData
>). If we look at the lexical transfer output which is internally coming from the bilingual dictionary for position 2, this will become clearer:<br
></br
><br
></br
><example
num="xStep4Diagram"
><single
><langData
lang="lVernacular"
>biti<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
> -&gt; be<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>cop</object
> <object
type="tluAffix"
>prs sg 2</object
><br
></br
>|                ||   |              |<br
></br
>|           person|   |              |<br
></br
>|_________________|   |______________|<br
></br
>  source language      target language</langData
><langData
lang="lVernacular"
></langData
></single
></example
>If we tried to clip from position 1 (<langData
lang="lVernacular"
>Otići<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pfv ptcp_f_sg</object
></langData
>), we would get no result for the person attribute because the verb in position 1 does not contain any tags which match the tags in the definition for person.<br
></br
><br
></br
></li
><li
>Now test it in the <object
type="tLiveRuleTester"
></object
>. (Go back to having just <object
type="tItalic"
>Otišla</object
> and <object
type="tItalic"
>si</object
> checked.)<br
></br
><p
>The result is:</p
><example
num="xStep4Target"
><single
><langData
lang="lVernacular"
>propers<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>pro</object
> <object
type="tluAffix"
>nom 2 sg</object
> Leave<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>pst</object
></langData
></single
></example
><p
>Select all the Croatian words, do <object
type="tBold"
>Transfer</object
> and <object
type="tBold"
>Synthesize</object
> and see what our English sentence looks like.</p
><p
>Now we get:</p
><example
num="xOutputStep4"
><single
><langData
lang="lVernacular"
>you Left quietly and without wordgen sg</langData
></single
></example
><p
>We get the second person singular pronoun that we wanted, but this is not totally satisfying because <object
type="tItalic"
>you</object
> should be capitalized and <object
type="tItalic"
>Left</object
> should not be. Let’s fix that.</p
><ol
><li
>We want to be careful, because we don’t want <object
type="tItalic"
>you</object
> capitalized in all circumstances. For example, if the Croatian past tense clause is embedded in another phrase, the first word may not be capitalized. What we can do is check what the capitalization of the verb is and apply that same capitalization to the pronoun. Make your <object
type="tRuleElemInXXE"
>lexical unit</object
> element look like <exampleRef
letter="xGetCase1"
num="xGetCase1"
></exampleRef
>:<example
num="xGetCase1"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutGetCase1.PNG"
></img
></chart
></example
>Notice how the literal string element is indented under the <object
type="tRuleElemInXXE"
>get case from</object
> element. This means that it is a child element of the <object
type="tRuleElemInXXE"
>get case from</object
> element. To accomplish this, <object
type="tXMLmindXMLEditor"
></object
> has a way to wrap an element around another element. This is what you do.<ol
><li
>Click on the words “literal string”. The whole element becomes outlined in a red rectangle.</li
><li
>Either right-click and choose Convert [wrap]... or click on the <img
src="Images/ButWrap.PNG"
></img
> button (upper right side) or press Ctrl-Shift-T.</li
><li
>At this point a list of elements to insert shows up in the upper right pane. Choose <object
type="tItalic"
>get-case-from</object
>.</li
><li
>Now set the <object
type="tRuleElemInXXE"
>item</object
> property to 1 and we will be getting the capitalization from the first word.<br
></br
><br
></br
></li
></ol
></li
><li
>Now we need to make the second lexical unit come out with the first letter in lower case. We could use the <object
type="tRuleElemInXXE"
>modify-case</object
> element, but we would have to add a new statement above the <object
type="tRuleElemInXXE"
>output</object
> element. Instead we can just use the same method as above to get the case from the second word. This time wrap the <object
type="tRuleElemInXXE"
>get case from</object
> element around the <object
type="tRuleElemInXXE"
>clip</object
> element that copies the lemma. This is shown below: <example
num="xGetCase2"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutGetCase2.PNG"
></img
></chart
></example
><object
type="tItalic"
>Trick: Click on the word "clip" and type Ctrl-a. This will execute the last command you did in the <object
type="tXMLmindXMLEditor"
></object
> again (namely wrap an element with the <object
type="tRuleElemInXXE"
>get case from</object
> element.)</object
></li
></ol
><p
><object
type="tBold"
>Transfer</object
> and <object
type="tBold"
>Synthesize</object
> again.</p
><p
>Now we get:</p
><example
num="xOutputStep4b"
><single
><langData
lang="lVernacular"
>You left quietly and without wordgen sg</langData
></single
></example
><p
>Looking good!</p
></li
></ol
></section4
><section4
id="step5"
><secTitle
>Step 5</secTitle
><p
>The last remaining thing to do is to not output the genitive or singular tags on the noun. We’re going to have to make a whole new rule to match nouns.</p
><ol
><li
>Define a category for nouns.<example
num="xCatN"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutCatN.PNG"
></img
></chart
></example
></li
><li
>Make a new rule which matches nouns as defined by the previous category. To start with, we’ll just output the whole lexical unit. <example
num="xRuleN"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutRuleN.PNG"
></img
></chart
></example
></li
><li
>Add nouns to the grammatical <object
type="tRuleElemInXXE"
>category attribute</object
> element. Now it looks like this:<example
num="xAttrWithN"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutAttrGramCatWNoun.PNG"
></img
></chart
></example
></li
><li
>Adjust the rule to output only the lemma and grammatical category.<example
num="xLexUnitNoun"
><chart
><img
cssSpecial="Height:60%"
src="Images/RulesTutLexUnitNoun1.PNG"
></img
></chart
></example
><p
>Now test it in the <object
type="tLiveRuleTester"
></object
>, but this time check only the Croatian word <object
type="tItalic"
>pozdrava</object
>.</p
><p
>Starting with:</p
><example
num="xStep5Source"
><single
><langData
lang="lVernacular"
>pozdrav<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>gen_sg</object
></langData
></single
></example
><p
>The result is:</p
><example
num="xStep5Target"
><single
><langData
lang="lVernacular"
>word<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
></langData
></single
></example
><p
>And if we <object
type="tBold"
>Synthesize</object
> we get:</p
><example
num="xStep5aTarget"
><single
><langData
lang="lVernacular"
>word</langData
></single
></example
><p
>Close the <object
type="tLiveRuleTester"
></object
> and run the modules in the <object
type="tCollection"
>FlexTrans All Steps</object
> to see what our English sentence looks like.</p
><p
>Now we get:</p
><example
num="xOutputStep5"
><single
><gloss
lang="lGloss"
>You left quietly and without word</gloss
></single
></example
><p
>Success!</p
></li
></ol
></section4
><section4
id="step6"
><secTitle
>Step 6</secTitle
><p
>Step 6 is left as an exercise for the reader. Change the noun rule to output an indefinite article before the noun. You can do this by following the instructions for adding the pronoun, see <sectionRef
sec="step4"
showTitle="full"
textBefore="none"
></sectionRef
>. The string you need to output is <langData
lang="lVernacular"
>a<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>indf</object
></langData
>.</p
><p
>You can find the solution transfer file called <object
type="tFilename"
>solution.t1x</object
> in the <object
type="tFoldername"
>FLExTrans Documentation\Transfer Rules Tutorial</object
> folder.</p
><p
>You may think this was a lot of work to translate one sentence from Croatian to English, but consider the fact that now every Croatian past tense construction that occurs in a text will correctly be translated to English and every indefinite noun will also be handled.</p
></section4
></section3
></section2
></section1
><section1
id="sTestbed"
><secTitle
>The <object
type="tFlextrans"
></object
> <object
type="tTool"
>Testbed</object
></secTitle
><p
>The <object
type="tFlextrans"
></object
> <object
type="tTool"
>Testbed</object
> is a system designed to help you maintain the quality of your translations. It not uncommon, as you add new transfer rules to the system or change the lexicons, you mess up the results you were getting before. To help prevent this, it is very helpful to have a database of expected results for a certain inputs. This is called a testbed. After making significant changes to your translation system, you can re-run the testbed to make sure you are still getting the results you expect for words or sentences that you earlier deemed correct.</p
><section2
id="sTestbedWorkflow"
><secTitle
>Workflow with the <object
type="tTool"
>Testbed</object
></secTitle
><p
>This is the way you normally work with the testbed:</p
><ol
><li
>Make a change to the system, e.g. add a new rule or other changes.</li
><li
>Use the <object
type="tLiveRuleTester"
></object
> to verify you are getting the results you expect.</li
><li
>Click the <object
type="tButton"
>Add to Testbed</object
> button to add one or more tests that prove source words are correctly translating to the target.</li
><li
>Now run the testbed to verify that all your previous tests still give the expected result.<ol
><li
>Open the <object
type="tCollection"
>FLExTrans Run Testbed</object
> collection.</li
><li
>Click the <object
type="tButton"
>Run All</object
> button to run all the modules.</li
><li
>Review the <object
type="tTool"
>Testbed Log</object
> which will open at the end and show you the results of running the testbed.</li
></ol
></li
><li
>Make any adjustments as needed. Repeat. If you need to edit the testbed, open the file <object
type="tFilename"
>testbed.xml</object
> which is in the top-level folder in the <object
type="tXMLmindXMLEditor"
></object
>.</li
></ol
></section2
><section2
id="sTestbedTools"
><secTitle
><object
type="tTool"
>Testbed</object
> Tools</secTitle
><p
><object
type="tFlextrans"
></object
> has a collection of tools to help you maintain the testbed, run the testbed and see the results.</p
><section3
id="sTestbedLogViewer"
><secTitle
><object
type="tTool"
>Testbed Log Viewer</object
></secTitle
><p
>This module you will find in both the <object
type="tCollection"
>Tools</object
> and <object
type="tCollection"
>FLExTrans Run Testbed</object
> collections. Simply run the module and you will see a log of all the times the testbed has been run with a summary of the results. The most recently run test opens and lets you see the details for each test. Hover over the Source Lexical Units of a test to see some pop-up text of which <object
type="tFlexx"
></object
> source text the words came from. If the rule was invalid, the pop-up text will also tell you why <object
type="tFlextrans"
></object
> found the test invalid.</p
><example
num="xViewerImage"
><chart
><img
XeLaTeXSpecial="scaled='700'"
cssSpecial=" height:70%"
src="Images/TestbedLogViewer.PNG"
></img
></chart
></example
></section3
><section3
id="sStartTestbed"
><secTitle
><object
type="tTool"
>Start Testbed</object
></secTitle
><p
>This module you will find at the top of the <object
type="tCollection"
>FLExTrans Run Testbed</object
> collection. It initializes a test run and dumps all of the source lexical units in the testbed into the <object
type="tFilename"
>source_text.aper</object
> file.</p
></section3
><section3
id="sEndTestbed"
><secTitle
><object
type="tTool"
>End Testbed</object
></secTitle
><p
>This module you will find as the next to last module in the <object
type="tCollection"
>FLExTrans Run Testbed</object
> collection. It takes the results of running the transfer and synthesis processes (the <object
type="tFilename"
>source_text.aper</object
> file) and adds the tests run and whether they passed or not to the testbed log.</p
></section3
><section3
id="sTestbedLRT"
><secTitle
><object
type="tLiveRuleTester"
></object
></secTitle
><p
>The <object
type="tLiveRuleTester"
></object
> is a good place to add new tests to the testbed. See <sectionRef
sec="sRuleTester"
showTitle="full"
></sectionRef
> for more details.</p
></section3
><section3
id="sTestbedEditor"
><secTitle
>Testbed Editing</secTitle
><p
>It’s easiest to add new tests to the testbed while in the <object
type="tLiveRuleTester"
></object
>. If you need to edit or delete a test, edit the file <object
type="tFilename"
>testbed.xml</object
> in the top-level folder with the <object
type="tXMLmindXMLEditor"
></object
>.</p
></section3
></section2
></section1
><section1
id="sHowTo"
><secTitle
><object
type="tFlextrans"
></object
> How To’s</secTitle
><section2
id="sOneVerse"
><secTitle
>Complete Process for Translating One Verse (video)</secTitle
><p
><link
href="https://drive.google.com/file/d/1KibhaxIHRPYM8SXiWxYcaxSgxHOlt1fv/view?usp=sharing"
><img
cssSpecial=" height:30%"
src="Images\CompleteVerseVideo.png"
></img
></link
></p
></section2
><section2
id="sTransferRuleHowTos"
><secTitle
>Transfer Rule How To’s</secTitle
><p
><comment
>How to use a variable. How to run rule logic on subset of entries (how do I use a list). How to save the fact that a word occurred in a sentence (How to use a flag) How to check if the end of the sentence has been reached. How to use 'and', 'or' and 'not' as part of the choose logic. How to use inflection features and classes in rules. How do I get the upper case at the beginning of the sentence. How do I enter a comment in my transfer rules?</comment
></p
><section3
id="sCategory"
><secTitle
>How do I use the category element in the transfer rules?</secTitle
><p
>Lexical categories are used to group words together. The grouping can be very broad such as verbs or very specific such as pronouns with feminine suffixes. The categories are used in the pattern matching system of transfer rules.</p
><example
num="xCat"
><chart
><img
cssSpecial="Height:75%"
src="Images/CategoryEx.PNG"
></img
></chart
></example
><p
><exampleRef
letter="xCat"
num="xCat"
></exampleRef
> is an example of a lexical category for indefinite nominals. The period indicates where a new tag begins. The asterisk is a wildcard indicator. It means that anything can fill that position. An asterisk at the end of the item matches one or more final tags. For example, if I have the lexical unit <langData
lang="lVernacular"
>book</langData
><object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>f</object
> <object
type="tluAffix"
>sg</object
>, it could be precisely matched by a <object
type="tRuleElemInXXE"
>tags</object
> element containing <object
type="tCourier"
>n.f.sg</object
>. More generally we could match <langData
lang="lVernacular"
>book</langData
> with the <object
type="tRuleElemInXXE"
>tags</object
> element containing <object
type="tCourier"
>n.f.*</object
>. This would refer to all words that have the grammatical category <object
type="tluGrammCat"
>n</object
> followed by the tag <object
type="tluAffix"
>f</object
> followed by anything else, i.e. feminine nouns. <exampleRef
letter="xCat"
num="xCat"
></exampleRef
> defines the set of all indefinite nouns — words that have the grammatical category <object
type="tluGrammCat"
>n</object
> or <object
type="tluGrammCat"
>n-irreg</object
> followed by <object
type="tluAffix"
>ind</object
> and optionally something else afterward. Note that <object
type="tCourier"
>n.ind</object
> and <object
type="tCourier"
>n.ind.*</object
> are both necessary because <object
type="tCourier"
>n.ind.*</object
> would require some affix after <object
type="tluAffix"
>ind</object
> and not match an indefinite noun like <langData
lang="lVernacular"
>car</langData
><object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>n</object
> <object
type="tluAffix"
>ind</object
> that has no additional suffixes..</p
><p
>You can use the lemma element to identify a specific word-sense. <exampleRef
letter="xCatLem"
num="xCatLem"
></exampleRef
> shows how the category <object
type="tCourier"
>dem_this</object
> can be defined as a word that has a grammatical category of <object
type="tluGrammCat"
>dem</object
> and lemma <langData
lang="lVernacular"
>this</langData
><object
type="tSubscript"
>1.1</object
> (in <object
type="tFlexx"
></object
>: headword <langData
lang="lVernacular"
>this</langData
><object
type="tSubscript"
>1</object
> , sense 1). This might be useful when you want to match phrases containing the word <object
type="tCourier"
>this</object
>.</p
><example
num="xCatLem"
><chart
><img
cssSpecial="Height:75%"
src="Images/CategoryLemmaEx.PNG"
></img
></chart
></example
></section3
><section3
id="sAttribute"
><secTitle
>How do I use the attribute element in the transfer rules?</secTitle
><p
>Attributes are defined in the rule file in order to identify possible values for word characteristics. An example is shown in <exampleRef
letter="xAttrib"
num="xAttrib"
></exampleRef
>.</p
><example
num="xAttrib"
><chart
><img
cssSpecial="Height:75%"
src="Images/AttributeEx.PNG"
></img
></chart
></example
><p
>Certain words may have affixes that indicate grammatical number. <exampleRef
letter="xAttrib"
num="xAttrib"
></exampleRef
> defines the possible values for the number attribute as being sg (singular) or pl (plural). Like lexical categories, these refer to tags in the data stream. Attributes are used within rules to get or set values.</p
></section3
><section3
id="sPatternMatch"
><secTitle
>How does pattern matching work?</secTitle
><p
>The <object
type="tTool"
>Apertium</object
> transfer engine searches for patterns in your source text. The patterns it searches for are those defined for each rule you have. Some patterns may be one word, some patterns may be multiple words. The transfer engine tries to match the longest patterns first and then progressively goes to shorter and shorter patterns. This means a five-word pattern would be used before a three-word pattern (assuming a set of words would match both patterns.) When there are multiple patterns of the same length, the first one listed gets precedence. This means in some cases the order of your rules will be important.</p
><p
>The transfer engine searches for matches in your words in sequential order starting with the first word. It will never find a match at some point in a text and then go back earlier in the text.</p
><p
>Another important concept is that the transfer engine processes words just once for whatever pattern is matched. After they are processed, the words are not examined again for any other matches. In other words, patterns cannot apply in an overlapping manner. For example, if you have a rule that matches <object
type="tItalic"
>determiner-noun</object
> and another one that matches <object
type="tItalic"
>noun-adjective</object
>, when a sentence of the form <object
type="tItalic"
>determiner-noun-adjective</object
> is processed. The engine uses the rule that is listed first and then discards the three words and continues on to other words. The second rule does not get applied. Another way to describe it is to say that the engine processes words in distinct chunks.</p
><p
>If the <object
type="tTool"
>Apertium</object
> transfer engine finds a match, it runs the action part of your rule. If the engine finds no match for a word, it does default translation of it according to what is in the bilingual dictionary. Cf. <sectionRef
sec="sRulesApplied"
showTitle="full"
></sectionRef
>.</p
></section3
><section3
id="sDeleteWord"
><secTitle
>How do I delete a word from the target output? (How do I prevent a source word from being transferred to the target text?)</secTitle
><p
>The short answer is don’t output it. In other words, don’t declare that it should be outputted into the target data stream.</p
><p
>When you match two or more words in the <object
type="tRuleElemInXXE"
>pattern</object
> section of a transfer rule, you can choose to only list some of the words in the <object
type="tRuleElemInXXE"
>output</object
> section. This is exactly what we did in <sectionRef
sec="step1"
showTitle="full"
textBefore="useDefault"
></sectionRef
> of the tutorial. In <exampleRef
letter="xOutput1"
num="xOutput1"
></exampleRef
> we only declared that the word in <object
type="tRuleElemInXXE"
>position</object
> 1 should be outputted.</p
></section3
><section3
id="sInsertWord"
><secTitle
>How do I insert a word into the target output?</secTitle
><p
>Naturally to add something to the target output, we need to add something to the <object
type="tRuleElemInXXE"
>output</object
> part of our transfer rule. And what goes in <object
type="tRuleElemInXXE"
>output</object
> part the of our transfer rule? Lexical units. We need to insert a lexical unit block under the <object
type="tRuleElemInXXE"
>output</object
> element of our transfer rule. <object
type="tUnderline"
>The bare minimum we need for a lexical unit is the word-sense and the grammatical category.</object
> If we are manually outputting a word-sense, we need to use a <object
type="tRuleElemInXXE"
>literal string</object
> element and the text needs to be of the form word1.2. Where 1 would be the homograph number (if there isn’t one in FLEx, use 1) and 2 would be the sense number. In this case the second sense of the word. <exampleRef
letter="xInsertWord"
num="xInsertWord"
></exampleRef
> shows how it might look.</p
><example
num="xInsertWord"
><chart
><img
cssSpecial="Height:75%"
src="Images/InsertWord.png"
></img
></chart
></example
><p
>Of course you can output affixes or clitics as well. These would be additional <object
type="tRuleElemInXXE"
>literal string</object
> elements. Remember the first literal tag is the grammatical category, all subsequent tags are affixes and the like. If you have a valid word-sense and its corresponding grammatical category, FLExTrans will look up this word-sense in the target FLEx lexicon and use it in the final synthesis process.</p
><p
>If you have other lexical units that you will be outputting, remember to put a <object
type="tRuleElemInXXE"
>blank space</object
> element so that you get a space between your words. This is shown in <exampleRef
letter="xLexUnitPron"
num="xLexUnitPron"
></exampleRef
>. <sectionRef
sec="step4"
showTitle="full"
></sectionRef
> of the transfer rules tutorial shows an example of inserting a word into the target output.</p
></section3
><section3
id="sDeleteAffix"
><secTitle
>How do I delete an affix?</secTitle
><p
>There are two methods for deleting an affix. You can either set the value for that affix (attribute) to blank or you can not declare that the affix (attribute) gets outputted.</p
><ol
><li
>Method 1. Use the <object
type="tRuleElemInXXE"
>let</object
> element to set an attribute’s value to blank. See <exampleRef
letter="xLetBlank"
num="xLetBlank"
></exampleRef
>.<example
num="xLetBlank"
><chart
><img
cssSpecial="Height:67%"
src="Images/LetBlank.PNG"
></img
></chart
></example
>Here we are overriding whatever is in the tense attribute (a_tense) with a blank string. Whenever the tense affix gets outputted, it will be outputted as nothing. As an example, in <exampleRef
letter="xOutputWhole"
num="xOutputWhole"
></exampleRef
> the whole word is outputted with all its attributes.<example
num="xOutputWhole"
><chart
><img
cssSpecial="Height:75%"
src="Images/OutputWholeWord.PNG"
></img
></chart
></example
></li
><li
>Method 2. In the <object
type="tRuleElemInXXE"
>Output</object
> element, explicitly declare each attribute of the word that you want to output. Don’t include the attribute that needs to be deleted.<example
num="xOutMultAffixes"
><chart
><img
cssSpecial="Height:75%"
src="Images/OutputMultAffixes.PNG"
></img
></chart
></example
>In <exampleRef
letter="xOutMultAffixes"
num="xOutMultAffixes"
></exampleRef
> you can see that the lemma is outputted and then the grammatical category and then two attribute. The disadvantage of this method is that you have to explicitly declare every possible attribute that could occur. Where as in <exampleRef
letter="xOutputWhole"
num="xOutputWhole"
></exampleRef
> in Method 1, you just have to output the whole word.</li
></ol
></section3
><section3
id="sCondLogic"
><secTitle
>How do I use conditional logic in a transfer rule? (How do I say if this ... then that?) (video)<img
src="Images/VideoIcon.PNG"
></img
></secTitle
><p
>In the transfer rules you have the ability to use conditional logic. Please watch this <link
href="https://drive.google.com/open?id=1gu5xDKdDzPu4yvFui2xakhnwAjNmF2Rm"
>video</link
> for an explanation.</p
></section3
><section3
id="sMacro"
><secTitle
>How do I use a macro? (How can I repeat rule statements in multiple places?) (video)<img
src="Images/VideoIcon.PNG"
></img
></secTitle
><p
>In the transfer rules you have the ability to modularize your rules by putting repeated logic into a macro. Please watch this <link
href="https://drive.google.com/open?id=1ptqz64B_X8eYnhaHnUEvCXRc7LFj-0kt"
>video</link
> for an explanation.</p
></section3
><section3
id="sAgreement"
><secTitle
>How do I handle noun agreement? (How do I get a target word or words to agree with a noun?) (video)<img
src="Images/VideoIcon.PNG"
></img
></secTitle
><p
>One main strategy for getting words to agree with a noun, is to make sure features are assigned to the noun and then in the transfer rules make the needed adjustment to the words you output depending on what the feature values (or class values) are.</p
><p
>To see how to do this in a sample language pair, please watch <link
href="https://drive.google.com/open?id=18D-P4pdXwotGGdRNBO5fYcIhZWzHT0OA"
>video 1</link
> and <link
href="https://drive.google.com/open?id=13jWg2lGI9yX74DhLRf0XO24KG9QWalC_"
>video 2</link
>.</p
><p
>If you would like to try creating the rules along with the video, please follow the instructions in the file: <object
type="tFilename"
>Readme.txt</object
> in the <object
type="tFoldername"
>Doc\Agreement</object
> folder. See the file <object
type="tFilename"
>transfer_rules - solution.t1x</object
> which shows the form of the rules shown in the video.</p
></section3
></section2
><section2
id="sOther"
><secTitle
>Other How To’s</secTitle
><p
></p
><section3
id="sViewBiling"
><secTitle
>How do I view the bilingual lexicon?</secTitle
><p
>You can view the bilingual lexicon by double-clicking on the file <object
type="tFilename"
>bilingual.dix</object
> in the <object
type="tFoldername"
>FlexTools\Output</object
> folder. An example portion of a bilingual lexicon is shown in <exampleRef
letter="xBilingEntries0"
num="xBilingEntries0"
></exampleRef
>.</p
><example
num="xBilingEntries0"
><chart
><img
src="Images/BilingalEntries2.PNG"
></img
></chart
></example
></section3
><section3
id="sRepl"
><secTitle
>I have a source word that maps to two different target words depending on the inflection of the source word. How do I handle that?</secTitle
><p
>You can handle this by using the <object
type="tFilename"
>replace.dix</object
> file to add additional mappings to the bilingual lexicon. This file is your install folder.</p
><p
>The bilingual lexicon is a mapping of source word-senses to target word-senses. There are no inflectional affixes present in the bilingual lexicon. That's the way <object
type="tFlextrans"
></object
> builds it. In theory, though, there could be inflectional features or classes present. An example portion of a bilingual lexicon is shown in <exampleRef
letter="xBilingEntries"
num="xBilingEntries"
></exampleRef
>. You can view the bilingual lexicon by double-clicking on the file <object
type="tFilename"
>bilingual.dix</object
> in the <object
type="tFoldername"
>FlexTools\Output</object
> folder. Both the <object
type="tFilename"
>replace.dix</object
> and <object
type="tFilename"
>bilingual.dix</object
> files are XML files and will load automatically in <object
type="tXMLmindXMLEditor"
></object
>.</p
><example
num="xBilingEntries"
><chart
><img
src="Images/BilingalEntries2.PNG"
></img
></chart
></example
><p
>In order to have a word map differently than what is in the bilingual lexicon, you need to add a line to the replacement file. If you double-click on <object
type="tFilename"
>replace.dix</object
> in the install folder, you will see something like <exampleRef
letter="xReplacement"
num="xReplacement"
></exampleRef
>.</p
><example
num="xReplacement"
><chart
><img
src="Images/Replacement_In_XXE2.PNG"
></img
></chart
></example
><p
>The replacement file has two main sections, one for replacing default bilingual entries with ones of your choice and one section for appending new entries to the bilingual lexicon. We are interested in doing the latter. Note, we can’t edit the bilingual dictionary file directly because it gets generated automatically by <object
type="tFlextrans"
> </object
>. After <object
type="tFlextrans"
></object
> generates it, <object
type="tFlextrans"
></object
> replaces and appends entries from the replacement file.</p
><p
>Let’s say that we want to map the past tense of the entry for <langData
lang="lVernacular"
>lieben</langData
> shown in <exampleRef
letter="xBilingEntries"
num="xBilingEntries"
></exampleRef
> to a different Swedish word, we change the replacement file to something like <exampleRef
letter="xRepChanged"
num="xRepChanged"
></exampleRef
>.</p
><example
num="xRepChanged"
><chart
><img
src="Images/ReplacementFileChanged2.PNG"
></img
></chart
></example
><p
>Let’s look closer at the last line. The <object
type="tRuleElemInXXE"
>left</object
> element has <langData
lang="lVernacular"
>lieben1.1</langData
> and the “symbol” <langData
lang="lVernacular"
>v</langData
> just like the bilingual file, but it also has a new symbol <langData
lang="lVernacular"
>pst</langData
>. This is the gloss for the past suffix in German. By adding this suffix, we are telling <object
type="tFlextrans"
></object
> that we are mapping the past inflection of <langData
lang="lVernacular"
>lieben1.1</langData
> to something else. The new Swedish word is listed for the <object
type="tRuleElemInXXE"
>right</object
> element. Note that we also had to add a new symbol definition, <langData
lang="lVernacular"
>pst</langData
> so that <object
type="tFlextrans"
></object
> knows the symbol is. Any symbols you use in a section of the replacement file, have to be defined under the <object
type="tRuleElemInXXE"
>Symbols</object
> element.</p
></section3
><section3
id="sInflVariantTgt"
><secTitle
>How do I handle inflectional variants in the target language? (video)<img
src="Images/VideoIcon.PNG"
></img
></secTitle
><p
>To learn how <object
type="tFlextrans"
></object
> can handle these kind of variants, please watch this <link
href="https://drive.google.com/open?id=13LVKJM7kx6MKwuUDBSfs58j8Hd4i5yd0"
>video</link
>.</p
><p
>The key thing in the techniques explained in the videos is to get inflectional features assigned to Irregularly Inflected Form variants that match exactly the suffixes that would normally be used.</p
><p
>If you would like to try doing the same thing while watching the video, please follow the instructions in the file: <object
type="tFilename"
>Readme.txt</object
> in the <object
type="tFoldername"
>Doc\Irregular Form</object
> folder.</p
></section3
><section3
id="sInflVariantSrc"
><secTitle
>How do I handle inflectional variants in the source language? (video)<img
src="Images/VideoIcon.PNG"
></img
></secTitle
><p
>To learn how <object
type="tFlextrans"
></object
> can handle these kind of variants, please watch this <link
href="https://drive.google.com/open?id=1_lqFLEmeBFTeJdoI101B5vId9zFer5Wt"
>video</link
>.</p
><p
>The key thing in the techniques explained in the videos is to get inflectional features assigned to Irregularly Inflected Form variants that match exactly the suffixes that would normally be used.</p
><p
>If you would like to try doing the same thing while watching the video, please follow the instructions in the file: <object
type="tFilename"
>Readme.txt</object
> in the <object
type="tFoldername"
>Doc\Irregular Form</object
> folder. Note: be sure to set the SourceTextName property in the configuration file to “Text2”.</p
></section3
></section2
></section1
><section1
id="sReferenceDocs"
><secTitle
>Reference documents</secTitle
><p
>The first version of <object
type="tFlextrans"
></object
> was produced as part of a Master’s Thesis see <citation
ref="rLockwood15"
></citation
>. In 2018 and 2021 Ron presented papers about <object
type="tFlextrans"
></object
> at the respective BT Conferences. See <citation
ref="rLockwood17"
></citation
> and <citation
ref="rLockwood21a"
></citation
>. Also in 2021 Ron presented on Syntactic Parsing as a front-end to <object
type="tFlextrans"
></object
>. See <citation
ref="rLockwood21b"
></citation
>.</p
></section1
><backMatter
><appendix
id="aAppend"
><secTitle
>Appendix</secTitle
><p
><comment
>Somewhere I need to mention that glosses have to be unique and no spaces. Or is it sufficient that the modules will warn about it?</comment
></p
><section1
id="sStartFlextools"
><secTitle
>Starting <object
type="tFlexxTools"
></object
></secTitle
><p
>Here are the steps:</p
><ol
><li
>Navigate to the installation folder (typically <object
type="tFilename"
>Documents\FlexTools2.0</object
>).</li
><li
>Double-click on the file <object
type="tBold"
>FlexTools.vbs</object
> (a Visual Basic script file).</li
><li
>The <object
type="tFlexxTools"
></object
> window should appear which will look something like <exampleRef
letter="xFirstStart"
num="xFirstStart"
></exampleRef
>.</li
></ol
></section1
><section1
id="sDataStreamFormat"
><secTitle
>Data Stream Format<comment
>put a footnote with explanation that this is how we used it in FLExTrans, the full format is described at: wiki.apertium.org/wiki/Apertium_stream_format</comment
></secTitle
><p
>The <genericTarget
id="gDataStream"
></genericTarget
><object
type="tTool"
>Apertium</object
> data stream format consists of one or more lexical units. In <object
type="tFlextrans"
></object
>, a lexical unit looks something like this:</p
><p
><langData
lang="lVernacular"
>take<object
type="tSubscript"
>1.1</object
> <object
type="tluGrammCat"
>v</object
> <object
type="tluAffix"
>3sg</object
><endnote
id="nToolToView"
><p
>You can use the <object
type="tTool"
>View Source/Target Apertium File Tool</object
> for a more friendly view of the data stream format found in the files <object
type="tFilename"
>source_text.aper</object
> and <object
type="tFilename"
>target_text.aper</object
>.</p
></endnote
><endnote
id="nRawDataStream"
><p
>In the plain format the stream format can be explained as follows:</p
><chart
><img
XeLaTeXSpecial="scaled='300'"
cssSpecial="width:60%"
src="Images/LexicalUnit.PNG"
></img
></chart
></endnote
></langData
></p
><p
>Where take<object
type="tSubscript"
>1</object
><endnote
id="nNoOneHomograph"
><p
>Technically <object
type="tFlexx"
></object
> only displays a subscript 1 if there is a homograph that exists with subscript 2. Without any homograph the <object
type="tFlexx"
></object
> headword is just plain -- without any subscript.</p
></endnote
> is the headword from <object
type="tFlexx"
></object
>. The 1.1 subscript means homograph one, sense one. The grammatical category is colored in blue and all other tags are colored in green.</p
></section1
></appendix
><endnotes
></endnotes
><references
><refAuthor
citename="Apertium,"
name="Apertium"
><refWork
id="rApertiumSite"
><refDate
>2021</refDate
><refTitle
>Apertium, A free/open-source machine translation platform</refTitle
><webPage
><url
>http://apertium.org</url
><dateAccessed
>12/20/2021</dateAccessed
></webPage
></refWork
></refAuthor
><refAuthor
citename="Forcada et al."
name="Forcada, Mikel L., Bonev, Boyan Ivanov, Rojas, Sergio Ortiz, Ortiz, Juan Antonio Perez, Sanchez, Gema Ramirez, Martinez, Felipe Sanchez, Armentano-Oller, Carme, Montava, Marco A., Tyers, Francis M."
><refWork
id="rApertium"
><refDate
>2010</refDate
><refTitle
>Documentation of the Open-Source Shallow-Transfer Machine Translation Platform Apertium</refTitle
><ms
><institution
>Departament de Llenguatges i Sistemes Informàtics Universitat d’Alacant</institution
></ms
><url
>http://xixona.dlsi.ua.es/~fran/apertium2-documentation.pdf</url
></refWork
></refAuthor
><refAuthor
citename="Lockwood"
name="Lockwood, Ronald Milton"
><refWork
id="rLockwood15"
><refDate
>2015</refDate
><refTitle
>A Linguist-Friendly Machine Translation System for Low-Resource Languages</refTitle
><ms
><institution
>University of Washington</institution
><url
>https://digital.lib.washington.edu/researchworks/handle/1773/33999</url
></ms
></refWork
></refAuthor
><refAuthor
citename="Lockwood"
name="Lockwood, Ron"
><refWork
id="rLockwood17"
><refDate
>2018</refDate
><refTitle
>Linguistically-Based Machine Translation with the New Tool FLExTrans</refTitle
><proceedings
><procCitation
page="pages unknown"
refToBook="rBTConference17"
></procCitation
></proceedings
></refWork
></refAuthor
><refAuthor
citename="Lockwood"
name="Lockwood, Ron"
><refWork
id="rLockwood21a"
><refDate
>2021a</refDate
><refTitle
>Results of Machine Translation with FLExTrans in Production-Mode</refTitle
><proceedings
><procCitation
page="pages unknown"
refToBook="rBTConference21"
></procCitation
></proceedings
></refWork
></refAuthor
><refAuthor
citename="Lockwood"
name="Lockwood, Ron"
><refWork
id="rLockwood21b"
><refDate
>2021b</refDate
><refTitle
>Using Syntactic Parsing to Enable Machine Translation for Language Pairs with Thorny Differences</refTitle
><proceedings
><procCitation
page="pages unknown"
refToBook="rBTConference21"
></procCitation
></proceedings
></refWork
></refAuthor
><refAuthor
citename="BTConf2017"
name="Bible Translation Conference 2017"
><refWork
id="rBTConference17"
><refDate
>2018</refDate
><refTitle
>Proceedings of Bible Translation 2017 Conference</refTitle
><book
><location
>Dallas</location
></book
></refWork
></refAuthor
><refAuthor
citename="BTConf2021"
name="Bible Translation Conference 2021"
><refWork
id="rBTConference21"
><refDate
>2021</refDate
><refTitle
>Proceedings of Bible Translation 2021 Conference</refTitle
><book
><location
>Online</location
></book
></refWork
></refAuthor
></references
></backMatter
><languages
><language
font-family="Courier New"
font-size="90%"
font-style="normal"
font-weight="bold"
id="lVernacular"
name="vernacular"
></language
><language
font-family="Times New Roman"
font-style="italic"
id="lGloss"
name="gloss"
></language
><language
id="en"
></language
><language
font-style="italic"
id="hr"
></language
></languages
><types
><comment
>The following types are provided as pre-set examples. You may well want to create your own types that refer to one or more of these. You do that by typing in the names of the types in the types attribute of your type.</comment
><type
font-weight="bold"
id="tBold"
></type
><type
font-style="italic"
font-weight="bold"
id="tBoldItalic"
></type
><type
font-weight="bold"
id="tEmphasis"
></type
><type
id="tGrammaticalGloss"
types="tSmallCaps"
></type
><type
font-style="italic"
id="tItalic"
></type
><type
cssSpecial="text-decoration:none"
id="tNoOverline"
xsl-foSpecial="text-decoration=&quot;no-overline&quot;"
></type
><type
font-variant="normal"
id="tNoSmallCaps"
></type
><type
cssSpecial="text-decoration:none"
id="tNoStrikethrough"
xsl-foSpecial="text-decoration=&quot;no-line-through&quot;"
></type
><type
cssSpecial="text-decoration:none"
id="tNoUnderline"
xsl-foSpecial="text-decoration=&quot;no-underline&quot;"
></type
><type
cssSpecial="text-decoration:overline"
id="tOverline"
xsl-foSpecial="text-decoration=&quot;overline&quot;"
></type
><type
font-style="normal"
font-variant="normal"
font-weight="normal"
id="tRegular"
></type
><type
font-family="Charis SIL Small Caps"
id="tSmallCaps"
></type
><type
XeLaTeXSpecial="line-through"
cssSpecial="text-decoration:line-through"
id="tStrikethrough"
xsl-foSpecial="text-decoration=&quot;line-through&quot;"
></type
><type
XeLaTeXSpecial="subscript"
cssSpecial="vertical-align:sub;"
font-size="65%"
id="tSubscript"
xsl-foSpecial="baseline-shift='sub'"
></type
><type
XeLaTeXSpecial="superscript"
cssSpecial="vertical-align:super;"
font-size="65%"
id="tSuperscript"
xsl-foSpecial="baseline-shift='super'"
></type
><type
XeLaTeXSpecial="underline"
cssSpecial="text-decoration:underline"
id="tUnderline"
xsl-foSpecial="text-decoration=&quot;underline&quot;"
></type
><comment
>Add your custom types here.'</comment
><type
font-style="normal"
font-weight="bold"
id="tButton"
></type
><type
color="#660066"
font-family="Arial"
font-size="80%"
font-style="normal"
font-weight="bold"
id="tCollection"
></type
><type
font-family="Courier New"
font-size="100%"
id="tCourier"
></type
><type
font-style="italic"
id="tFilename"
></type
><type
after="FLExTrans"
id="tFlextrans"
types="tTool"
></type
><type
after="FLExTools"
id="tFlexxTools"
types="tTool"
></type
><type
after="FLEx"
id="tFlexx"
types="tTool"
></type
><type
font-family="Tahoma"
font-size="80%"
font-style="normal"
font-weight="normal"
id="tFoldername"
></type
><type
after="Live Rule Tester Tool"
id="tLiveRuleTester"
types="tTool"
></type
><type
color="#000066"
id="tProgramName"
types="tBold"
></type
><type
color="#00B050"
font-family="Courier New"
font-size="90%"
id="tluAffix"
></type
><type
color="#0070c0"
font-family="Courier New"
font-size="90%"
id="tluGrammCat"
></type
><type
color="#FF0000"
font-family="Courier New"
font-size="90%"
id="tluNotFound"
></type
><type
color="#FFC000"
font-family="Courier New"
font-size="90%"
id="tluPunctuation"
></type
><type
color="navy"
font-family="Courier New"
font-weight="bold"
id="tModule"
></type
><type
font-style="normal"
font-weight="normal"
id="tNoItalic"
></type
><type
color="#006633"
font-family="Arial"
font-size="80%"
id="tRuleElemInXXE"
types="tBold"
></type
><type
after="Sense Linker Tool"
id="tSenseLinker"
types="tTool"
></type
><type
after="Testbed"
id="tTestbed"
types="tTool"
></type
><type
color="navy"
font-family="Courier New"
font-weight="bold"
id="tTool"
></type
><type
after="Source/Target Viewer Tool"
id="tViewSrcTgt"
types="tTool"
></type
><type
after="XMLmind XML Editor"
id="tXMLmindXMLEditor"
types="tTool"
></type
></types
></lingPaper
>
